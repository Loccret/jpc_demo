{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Generative PC on MNIST\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thebuckleylab/jpc/blob/main/examples/unsupervised_generative_pc.ipynb)\n",
    "\n",
    "This notebook demonstrates how to train a simple feedforward network with predictive coding to encode MNIST digits in an unsupervised manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install torch==2.3.1\n",
    "# !pip install torchvision==0.18.1\n",
    "# !pip install matplotlib==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpc\n",
    "\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "import optax\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')  # ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We define some global parameters, including the network architecture, learning rate, batch size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "INPUT_DIM = 50\n",
    "WIDTH = 300\n",
    "DEPTH = 3\n",
    "OUTPUT_DIM = 784\n",
    "ACT_FN = \"relu\"\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "MAX_T1 = 100\n",
    "N_TRAIN_ITERS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Some utils to fetch and plot MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mnist_loaders(batch_size):\n",
    "#     train_data = MNIST(train=True, normalise=True)\n",
    "#     test_data = MNIST(train=False, normalise=True)\n",
    "#     train_loader = DataLoader(\n",
    "#         dataset=train_data,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         drop_last=True\n",
    "#     )\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=test_data,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         drop_last=True\n",
    "#     )\n",
    "#     return train_loader, test_loader\n",
    "\n",
    "\n",
    "# class MNIST(datasets.MNIST):\n",
    "#     def __init__(self, train, normalise=True, save_dir=\"data\"):\n",
    "#         if normalise:\n",
    "#             transform = transforms.Compose(\n",
    "#                 [\n",
    "#                     transforms.ToTensor(),\n",
    "#                     transforms.Normalize(\n",
    "#                         mean=(0.1307), std=(0.3081)\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#         else:\n",
    "#             transform = transforms.Compose([transforms.ToTensor()])\n",
    "#         super().__init__(save_dir, download=True, train=train, transform=transform)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img, _ = super().__getitem__(index)\n",
    "#         img = torch.flatten(img)\n",
    "#         return img\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(labels, n_classes=10):\n",
    "    arr = torch.eye(n_classes)\n",
    "    return arr[labels]\n",
    "\n",
    "\n",
    "class MNIST(datasets.MNIST):\n",
    "    def __init__(self, train, normalise=True, save_dir=\"data\"):\n",
    "        if normalise:\n",
    "            transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=(0.1307), std=(0.3081)\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "        super().__init__(save_dir, download=True, train=train, transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super().__getitem__(index)\n",
    "        img = torch.flatten(img)\n",
    "        label = one_hot(label)\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "\n",
    "def get_mnist_loaders(batch_size):\n",
    "    train_data = MNIST(train=True, normalise=True)\n",
    "    test_data = MNIST(train=False, normalise=True)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_energies(energies, ts):\n",
    "    t_max = int(ts[0])\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=len(energies)-1)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    cmap_blues = plt.get_cmap(\"Blues\")\n",
    "    cmap_reds = plt.get_cmap(\"Reds\")\n",
    "    cmap_greens = plt.get_cmap(\"Greens\")\n",
    "    \n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    for t, energies_iter in enumerate(energies):\n",
    "        line1, = ax.plot(energies_iter[0, :t_max], color=cmap_blues(norm(t)))\n",
    "        line2, = ax.plot(energies_iter[1, :t_max], color=cmap_reds(norm(t)))\n",
    "        line3, = ax.plot(energies_iter[2, :t_max], color=cmap_greens(norm(t)))\n",
    "    \n",
    "        if t == 70:\n",
    "            legend_handles.append(line1)\n",
    "            legend_labels.append(\"$\\ell_1$\")\n",
    "            legend_handles.append(line2)\n",
    "            legend_labels.append(\"$\\ell_2$\")\n",
    "            legend_handles.append(line3)\n",
    "            legend_labels.append(\"$\\ell_3$\")\n",
    "    \n",
    "    ax.legend(legend_handles, legend_labels, loc=\"best\", fontsize=16)\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.get_cmap(\"Greys\"), norm=norm)\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"Training iteration\", fontsize=16, labelpad=14)\n",
    "    cbar.ax.tick_params(labelsize=14) \n",
    "    plt.gca().tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "    \n",
    "    ax.set_xlabel(\"Inference iterations\", fontsize=18, labelpad=14)\n",
    "    ax.set_ylabel(\"Energy\", fontsize=18, labelpad=14)\n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Network\n",
    "\n",
    "For `jpc` to work, we need to provide a network with callable layers. This is easy to do with the PyTorch-like [`nn.Sequential()`](https://docs.kidger.site/equinox/api/nn/sequential/#equinox.nn.Sequential) in [equinox](https://github.com/patrick-kidger/equinox). For example, we can define a ReLU MLP with two hidden layers as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-11-01 11:42:22,850:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(SEED)\n",
    "key, *subkeys = jax.random.split(key, 4)\n",
    "network = [\n",
    "    nn.Sequential(\n",
    "        [\n",
    "            nn.Linear(10, 300, key=subkeys[0]),\n",
    "            nn.Lambda(jax.nn.relu)\n",
    "        ],\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        [\n",
    "            nn.Linear(300, 300, key=subkeys[1]),\n",
    "            nn.Lambda(jax.nn.relu)\n",
    "        ],\n",
    "    ),\n",
    "    nn.Linear(300, 784, key=subkeys[2]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use [`jpc.make_mlp()`](https://thebuckleylab.github.io/jpc/api/Utils/#jpc.make_mlp) to define a multi-layer perceptron (MLP) or fully connected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "  layers=(\n",
      "    Lambda(fn=Identity()),\n",
      "    Linear(\n",
      "      weight=f32[300,50],\n",
      "      bias=f32[300],\n",
      "      in_features=50,\n",
      "      out_features=300,\n",
      "      use_bias=True\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  layers=(\n",
      "    Lambda(fn=<PjitFunction of <function relu at 0x7500fa036de0>>),\n",
      "    Linear(\n",
      "      weight=f32[300,300],\n",
      "      bias=f32[300],\n",
      "      in_features=300,\n",
      "      out_features=300,\n",
      "      use_bias=True\n",
      "    )\n",
      "  )\n",
      "), Sequential(\n",
      "  layers=(\n",
      "    Lambda(fn=<PjitFunction of <function relu at 0x7500fa036de0>>),\n",
      "    Linear(\n",
      "      weight=f32[784,300],\n",
      "      bias=f32[784],\n",
      "      in_features=300,\n",
      "      out_features=784,\n",
      "      use_bias=True\n",
      "    )\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "network = jpc.make_mlp(\n",
    "    key,\n",
    "    input_dim=INPUT_DIM,\n",
    "    width=WIDTH,\n",
    "    depth=DEPTH,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    act_fn=ACT_FN,\n",
    "    use_bias=True\n",
    ")\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train\n",
    "\n",
    "A PC network can be updated in a single line of code with [`jpc.make_pc_step()`](https://thebuckleylab.github.io/jpc/api/Training/#jpc.make_pc_step), which is already \"jitted\" for optimised performance. To train in an unsupervised way, we simply avoid providing an `input` to [`jpc.make_pc_step()`](https://thebuckleylab.github.io/jpc/api/Training/#jpc.make_pc_step). To test the learned encoding or representation for downstream accuracy, you could simply add a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(key, layer_sizes, batch_size, network, test_loader, max_t1):\n",
    "    test_acc = 0\n",
    "    for _, (img_batch, label_batch) in enumerate(test_loader):\n",
    "        img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n",
    "\n",
    "        acc, img_preds = jpc.test_generative_pc(\n",
    "            model=network,\n",
    "            input=label_batch,\n",
    "            output=img_batch,\n",
    "            key=key,\n",
    "            layer_sizes=layer_sizes,\n",
    "            batch_size=batch_size,\n",
    "            max_t1=max_t1\n",
    "        )\n",
    "        test_acc += acc\n",
    "\n",
    "    avg_test_acc = test_acc / len(test_loader)\n",
    "\n",
    "    return avg_test_acc, label_batch, img_preds\n",
    "\n",
    "\n",
    "def train(\n",
    "    key,\n",
    "    input_dim,\n",
    "    width,\n",
    "    depth,\n",
    "    output_dim,\n",
    "    batch_size,\n",
    "    network,\n",
    "    lr,\n",
    "    max_t1,\n",
    "    n_train_iters\n",
    "):\n",
    "    layer_sizes = [input_dim] + [width]*(depth-1) + [output_dim]\n",
    "    optim = optax.adam(lr)\n",
    "    opt_state = optim.init(\n",
    "        (eqx.filter(network, eqx.is_array), None)\n",
    "    )\n",
    "    train_loader, test_loader = get_mnist_loaders(batch_size)\n",
    "\n",
    "    train_energies, ts = [], []\n",
    "    for iter, single_batch in enumerate(train_loader):\n",
    "        img_batch, _ = single_batch\n",
    "        img_batch = img_batch.numpy()\n",
    "\n",
    "\n",
    "        result = jpc.make_pc_step(\n",
    "            key=key,\n",
    "            layer_sizes=layer_sizes,\n",
    "            batch_size=batch_size,\n",
    "            model=network,\n",
    "            optim=optim,\n",
    "            opt_state=opt_state,\n",
    "            output=img_batch,\n",
    "            max_t1=max_t1,\n",
    "            record_activities=True,\n",
    "            record_energies=True\n",
    "        )\n",
    "        network, opt_state = result[\"model\"], result[\"opt_state\"]\n",
    "        train_energies.append(result[\"energies\"])\n",
    "        ts.append(result[\"t_max\"])\n",
    "\n",
    "        if ((iter+1) % 200) == 0 or (iter+1) == n_train_iters:\n",
    "            avg_test_acc, test_label_batch, img_preds = evaluate(\n",
    "                key,\n",
    "                layer_sizes,\n",
    "                batch_size,\n",
    "                network,\n",
    "                test_loader,\n",
    "                max_t1=max_t1\n",
    "            )\n",
    "            print(\n",
    "                f\"Train iter {iter+1}, train loss={result['loss']:4f}, \"\n",
    "                f\"avg test accuracy={avg_test_acc:4f}\"\n",
    "            )\n",
    "            if (iter+1) >= n_train_iters:\n",
    "                break\n",
    "    return result[\"model\"], train_energies, ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "Below we simply plot the energy dynamics of each layer during both inference and learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (50,) and (10,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m network, energies, ts = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINPUT_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWIDTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEPTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_t1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_T1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_train_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRAIN_ITERS\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m plot_train_energies(energies, ts)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(key, input_dim, width, depth, output_dim, batch_size, network, lr, max_t1, n_train_iters)\u001b[39m\n\u001b[32m     61\u001b[39m ts.append(result[\u001b[33m\"\u001b[39m\u001b[33mt_max\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28miter\u001b[39m+\u001b[32m1\u001b[39m) % \u001b[32m200\u001b[39m) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28miter\u001b[39m+\u001b[32m1\u001b[39m) == n_train_iters:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     avg_test_acc, test_label_batch, img_preds = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_t1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_t1\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mavg test accuracy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m     )\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m+\u001b[32m1\u001b[39m) >= n_train_iters:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(key, layer_sizes, batch_size, network, test_loader, max_t1)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, (img_batch, label_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[32m      4\u001b[39m     img_batch, label_batch = img_batch.numpy(), label_batch.numpy()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     acc, img_preds = \u001b[43mjpc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_generative_pc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_t1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_t1\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     test_acc += acc\n\u001b[32m     17\u001b[39m avg_test_acc = test_acc / \u001b[38;5;28mlen\u001b[39m(test_loader)\n",
      "    \u001b[31m[... skipping hidden 18 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sakana/jpc_demo/jpc/_test.py:171\u001b[39m, in \u001b[36mtest_generative_pc\u001b[39m\u001b[34m(model, output, input, key, layer_sizes, batch_size, skip_model, loss_id, param_type, sigma, ode_solver, max_t1, dt, stepsize_controller, weight_decay, spectral_penalty, activity_decay)\u001b[39m\n\u001b[32m    156\u001b[39m input_preds = solve_inference(\n\u001b[32m    157\u001b[39m     params=params,\n\u001b[32m    158\u001b[39m     activities=activities,\n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m     activity_decay=activity_decay\n\u001b[32m    169\u001b[39m )[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    170\u001b[39m input_acc = compute_accuracy(\u001b[38;5;28minput\u001b[39m, input_preds)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m output_preds = \u001b[43minit_activities_with_ffwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_type\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[-\u001b[32m1\u001b[39m]\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m input_acc, output_preds\n",
      "    \u001b[31m[... skipping hidden 18 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sakana/jpc_demo/jpc/_core/_init.py:62\u001b[39m, in \u001b[36minit_activities_with_ffwd\u001b[39m\u001b[34m(model, input, skip_model, param_type)\u001b[39m\n\u001b[32m     53\u001b[39m     skip_model = [\u001b[38;5;28;01mNone\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(model)\n\u001b[32m     55\u001b[39m scalings = _get_param_scalings(\n\u001b[32m     56\u001b[39m     model=model, \n\u001b[32m     57\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m, \n\u001b[32m     58\u001b[39m     skip_model=skip_model, \n\u001b[32m     59\u001b[39m     param_type=param_type\n\u001b[32m     60\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m z1 = scalings[\u001b[32m0\u001b[39m] * \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skip_model[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m     z1 += vmap(skip_model[\u001b[32m0\u001b[39m])(\u001b[38;5;28minput\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/equinox/nn/_sequential.py:105\u001b[39m, in \u001b[36mSequential.__call__\u001b[39m\u001b[34m(self, x, state, key)\u001b[39m\n\u001b[32m    103\u001b[39m         x, state = layer(x, state=state, key=key)\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m sentinel:\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/equinox/nn/_linear.py:97\u001b[39m, in \u001b[36mLinear.__call__\u001b[39m\u001b[34m(self, x, key)\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mx must have scalar shape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m     x = jnp.broadcast_to(x, (\u001b[32m1\u001b[39m,))\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     99\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:579\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    577\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/jax/_src/numpy/tensor_contractions.py:243\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(a, b, precision, preferred_element_type)\u001b[39m\n\u001b[32m    241\u001b[39m a = lax.squeeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[32m    242\u001b[39m b = lax.squeeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m out = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m result = lax.transpose(out, perm)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal._convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[31m[... skipping hidden 8 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/jpc/lib/python3.11/site-packages/jax/_src/lax/lax.py:4647\u001b[39m, in \u001b[36m_dot_general_shape_rule\u001b[39m\u001b[34m(lhs, rhs, dimension_numbers, precision, preferred_element_type, out_sharding)\u001b[39m\n\u001b[32m   4644\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core.definitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[32m   4645\u001b[39m   msg = (\u001b[33m\"\u001b[39m\u001b[33mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4646\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4647\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[32m   4649\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs.shape, rhs.shape, dimension_numbers)\n",
      "\u001b[31mTypeError\u001b[39m: dot_general requires contracting dimensions to have the same shape, got (50,) and (10,)."
     ]
    }
   ],
   "source": [
    "network, energies, ts = train(\n",
    "    key=key,\n",
    "    input_dim=INPUT_DIM,\n",
    "    width=WIDTH,\n",
    "    depth=DEPTH,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    network=network,\n",
    "    lr=LEARNING_RATE,\n",
    "    max_t1=MAX_T1,\n",
    "    n_train_iters=N_TRAIN_ITERS\n",
    ")\n",
    "plot_train_energies(energies, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
