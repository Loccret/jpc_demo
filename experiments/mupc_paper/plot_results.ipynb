{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install plotly==5.24.1\n",
    "!pip install kaleido==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "os.environ[\"BROWSER_PATH\"] = \"/home/myhome/chrome-headless-shell/linux-132.0.6834.83/chrome-headless-shell-linux64/chrome-headless-shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hessian analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hessian_eigenvalues_slice(\n",
    "        hessian_eigenspectrum, \n",
    "        matrix_id,    \n",
    "        save_path,\n",
    "        width_slice=None, \n",
    "        n_hidden_slice=None\n",
    "):\n",
    "    widths = list(hessian_eigenspectrum.keys())\n",
    "    n_hiddens = list(hessian_eigenspectrum[2].keys())\n",
    "    fig = go.Figure()\n",
    "    n_bins = 50\n",
    "\n",
    "    colorscale = \"Blues\" if width_slice is not None else \"Reds\"\n",
    "    colors = pc.sample_colorscale(colorscale, len(widths)+3)[3:]\n",
    "    if width_slice is not None:\n",
    "        for i, width in enumerate(widths):\n",
    "            for j, n_hidden in enumerate(n_hiddens):    \n",
    "                if width == width_slice:\n",
    "                    fig.add_trace(\n",
    "                        go.Histogram(\n",
    "                            x=hessian_eigenspectrum[width][n_hidden],\n",
    "                            histnorm=\"probability\",\n",
    "                            nbinsx=n_bins,\n",
    "                            name=f\"$H=2^{{{j+1}}}$\",\n",
    "                            marker=dict(color=colors[j])\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    if n_hidden_slice is not None:\n",
    "        for i, n_hidden in enumerate(n_hiddens):    \n",
    "            for j, width in enumerate(widths):\n",
    "                if n_hidden == n_hidden_slice:\n",
    "                    fig.add_trace(\n",
    "                        go.Histogram(\n",
    "                            x=hessian_eigenspectrum[width][n_hidden],\n",
    "                            histnorm=\"probability\",\n",
    "                            nbinsx=n_bins,\n",
    "                            name=f\"$N=2^{{{j+1}}}$\",\n",
    "                            marker=dict(color=colors[j])\n",
    "                        )\n",
    "                    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        barmode=\"overlay\",\n",
    "        height=400,\n",
    "        width=550,\n",
    "        xaxis=dict(title=f\"$\\LARGE{{\\lambda({{{matrix_id}}})}}$\"),\n",
    "        yaxis=dict(\n",
    "            title=f\"Density (log)\",\n",
    "            type=\"log\",\n",
    "            exponentformat=\"power\",\n",
    "            dtick=1\n",
    "        ),\n",
    "        font=dict(size=18),\n",
    "        margin=dict(b=100)\n",
    "    )\n",
    "    fig.update_traces(opacity=0.75)\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_metric_phase_diagram(metric, metric_id, save_path, title=None, log=False):\n",
    "    n_widths, n_hiddens = metric.shape[0], metric.shape[1]\n",
    "\n",
    "    norm = mcolors.LogNorm() if log else None\n",
    "    im = plt.imshow(\n",
    "        metric, \n",
    "        origin=\"lower\", \n",
    "        interpolation=\"bicubic\",\n",
    "        norm=norm\n",
    "    )\n",
    "    plt.xlabel(\"$H$\", fontsize=30, labelpad=15)\n",
    "    plt.ylabel(\"$N$\", fontsize=30, labelpad=15)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=30, pad=20)\n",
    "    \n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\n",
    "        metric_id, \n",
    "        fontsize=30, \n",
    "        labelpad=15\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    \n",
    "    ax = plt.gca()    \n",
    "    xtick_positions = [i for i in range(n_widths)]\n",
    "    ytick_positions = [i for i in range(n_hiddens)]\n",
    "    tick_labels = [f\"$2^{i+1}$\" for i in range(n_hiddens)]\n",
    "    \n",
    "    ax.set_xticks(xtick_positions)\n",
    "    ax.set_yticks(ytick_positions)\n",
    "    ax.set_xticklabels(tick_labels, fontsize=16)\n",
    "    ax.set_yticklabels(tick_labels, fontsize=16)\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def get_act_fn_title(act_fn):\n",
    "    if act_fn == \"linear\":\n",
    "        return \"Linear\"\n",
    "    elif act_fn == \"tanh\":\n",
    "        return \"Tanh\"\n",
    "    elif act_fn == \"relu\":\n",
    "        return \"ReLU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"activity_hessian_results\"\n",
    "IN_OUT_DIMS = [\"width\"]\n",
    "ACT_FNS = [\"linear\", \"tanh\", \"relu\"]\n",
    "USE_SKIPS = [False]  #True\n",
    "WEIGHT_INITS = [\"orthogonal\"]#[\"one_over_N\", \"standard_gauss\", \"standard\", \"orthogonal\"]\n",
    "PARAM_TYPES = [\"sp\"]  #\"mupc\", \n",
    "ACTIVITY_DECAY = [0]\n",
    "WIDTHS = [2**i for i in range(1, 8)]\n",
    "N_HIDDENS = [2**i for i in range(1, 8)]\n",
    "N_SEEDS = 3\n",
    "\n",
    "N_slice, H_slice = 128, 128\n",
    "for in_out_dims in IN_OUT_DIMS:\n",
    "    print(f\"\\nin_out_dims: {in_out_dims}\")\n",
    "    for act_fn in ACT_FNS:\n",
    "        print(f\"\\n\\tact_fn: {act_fn}\")\n",
    "        act_fn_title = get_act_fn_title(act_fn)\n",
    "        for use_skips in USE_SKIPS:\n",
    "            print(f\"\\n\\t\\tuse_skips: {use_skips}\")\n",
    "            for weight_init in WEIGHT_INITS:\n",
    "                print(f\"\\n\\t\\t\\tweight_init: {weight_init}\")\n",
    "                for param_type in PARAM_TYPES:\n",
    "                    print(f\"\\n\\t\\t\\t\\tparam_type: {param_type}\")\n",
    "                    for activity_decay in ACTIVITY_DECAY:\n",
    "                        print(f\"\\n\\t\\t\\t\\t\\tactivity_decay: {activity_decay}\\n\")                        \n",
    "                        for seed in range(N_SEEDS):\n",
    "                            print(f\"\\t\\t\\t\\t\\t\\tseed: {seed}\")\n",
    "            \n",
    "                            # eigenspectra\n",
    "                            D_eigenvals, O_eigenvals = {}, {}\n",
    "                            H_num_eigenvals, H_theory_eigenvals = {}, {}\n",
    "                            \n",
    "                            # max & min eigens\n",
    "                            D_max_eigen = np.zeros((len(WIDTHS), len(N_HIDDENS)))\n",
    "                            O_max_eigen = np.zeros_like(D_max_eigen)\n",
    "                            H_num_max_eigen = np.zeros_like(D_max_eigen)\n",
    "                            H_theory_max_eigen = np.zeros_like(D_max_eigen)\n",
    "                            \n",
    "                            D_min_eigen = np.zeros_like(D_max_eigen)\n",
    "                            O_min_eigen = np.zeros_like(D_max_eigen)\n",
    "                            H_num_min_eigen = np.zeros_like(D_max_eigen)\n",
    "                            H_theory_min_eigen = np.zeros_like(D_max_eigen)\n",
    "                    \n",
    "                            # cond nums\n",
    "                            H_num_cond_num = np.zeros_like(D_max_eigen)\n",
    "                            H_theory_cond_num = np.zeros_like(D_max_eigen)\n",
    "                            \n",
    "                            for i, width in enumerate(WIDTHS):\n",
    "                                D_eigenvals[width] = {}\n",
    "                                O_eigenvals[width] = {}\n",
    "                                H_num_eigenvals[width] = {}\n",
    "                                H_theory_eigenvals[width] = {}\n",
    "                                for j, n_hidden in enumerate(N_HIDDENS):\n",
    "                                    save_path = os.path.join(\n",
    "                                        SAVE_DIR, \n",
    "                                        f\"{in_out_dims}_in_out_dims\",\n",
    "                                        act_fn,\n",
    "                                        \"no_biases/supervised\",\n",
    "                                        \"skips\" if use_skips else \"no_skips\",\n",
    "                                        f\"{weight_init}_weight_init\",\n",
    "                                        f\"{param_type}_param\",\n",
    "                                        f\"activity_decay_{activity_decay}\",\n",
    "                                        f\"width_{width}\", \n",
    "                                        f\"{n_hidden}_n_hidden\", \n",
    "                                        str(seed)\n",
    "                                    )\n",
    "                                    H_num_eigens = np.load(f\"{save_path}/num_hessian_eigenvals.npy\")\n",
    "                                    H_num_eigenvals[width][n_hidden] = H_num_eigens\n",
    "                                    H_num_max_eigen[i, j] = max(H_num_eigens)\n",
    "                                    H_num_min_eigen[i, j] = min(H_num_eigens)\n",
    "                                    \n",
    "                                    cond_num = np.abs(max(H_num_eigens))/np.abs(min(H_num_eigens))\n",
    "                                    H_num_cond_num[i, j] = cond_num\n",
    "                                    \n",
    "                                    if act_fn == \"linear\":\n",
    "                                        D_eigens = np.load(f\"{save_path}/theory_D_eigenvals.npy\")\n",
    "                                        O_eigens = np.load(f\"{save_path}/theory_O_eigenvals.npy\")\n",
    "                                        H_theory_eigens = np.load(f\"{save_path}/theory_hessian_eigenvals.npy\")\n",
    "                        \n",
    "                                        # full eigenspectra\n",
    "                                        D_eigenvals[width][n_hidden] = D_eigens\n",
    "                                        O_eigenvals[width][n_hidden] = O_eigens\n",
    "                                        H_theory_eigenvals[width][n_hidden] = H_theory_eigens\n",
    "                        \n",
    "                                        # max & min eigens\n",
    "                                        D_max_eigen[i, j] = max(D_eigens)\n",
    "                                        O_max_eigen[i, j] = max(O_eigens)        \n",
    "                                        H_theory_max_eigen[i, j] = max(H_theory_eigens)\n",
    "                                        \n",
    "                                        D_min_eigen[i, j] = min(D_eigens)\n",
    "                                        O_min_eigen[i, j] = min(O_eigens)        \n",
    "                                        H_theory_min_eigen[i, j] = min(H_theory_eigens)\n",
    "                        \n",
    "                                        # cond nums\n",
    "                                        H_theory_cond_num[i, j] = np.abs(max(H_theory_eigens))/np.abs(min(H_theory_eigens))\n",
    "    \n",
    "                            # H slices, max & min eigens, and condition number\n",
    "                            plot_hessian_eigenvalues_slice(\n",
    "                                H_num_eigenvals, \n",
    "                                matrix_id=\"H_{\\mathbf{z}}\", \n",
    "                                width_slice=N_slice, \n",
    "                                save_path=f\"{save_path}/H_num_eigenvals_N_{N_slice}.pdf\", \n",
    "                            )\n",
    "                            plot_hessian_eigenvalues_slice(\n",
    "                                H_num_eigenvals, \n",
    "                                matrix_id=\"H_{\\mathbf{z}}\", \n",
    "                                n_hidden_slice=H_slice, \n",
    "                                save_path=f\"{save_path}/H_num_eigenvals_H_{H_slice}.pdf\", \n",
    "                            )\n",
    "                            plot_metric_phase_diagram(\n",
    "                                H_num_max_eigen, \n",
    "                                \"$\\lambda_{max}(H_{\\mathbf{z}})$\", \n",
    "                                f\"{save_path}/H_num_max_eigen.pdf\"\n",
    "                            )\n",
    "                            plot_metric_phase_diagram(\n",
    "                                H_num_min_eigen, \n",
    "                                \"$\\lambda_{min}(H_{\\mathbf{z}})$\", \n",
    "                                f\"{save_path}/H_num_min_eigen.pdf\"\n",
    "                            )\n",
    "                            plot_metric_phase_diagram(\n",
    "                                H_num_cond_num, \n",
    "                                \"$\\kappa(H_{\\mathbf{z}})$\", \n",
    "                                f\"{save_path}/H_num_cond_num.pdf\",\n",
    "                                title=act_fn_title,\n",
    "                                log=False if (not use_skips and param_type == \"sp\") else True\n",
    "                            )\n",
    "                            \n",
    "                            if act_fn == \"linear\":\n",
    "                                # D & O slices\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    D_eigenvals, \n",
    "                                    matrix_id=\"D\", \n",
    "                                    width_slice=N_slice, \n",
    "                                    save_path=f\"{save_path}/D_eigenvals_N_{N_slice}.pdf\", \n",
    "                                )\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    O_eigenvals, \n",
    "                                    matrix_id=\"O\", \n",
    "                                    width_slice=N_slice, \n",
    "                                    save_path=f\"{save_path}/O_eigenvals_N_{N_slice}.pdf\", \n",
    "                                )\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    D_eigenvals, \n",
    "                                    matrix_id=\"D\", \n",
    "                                    n_hidden_slice=H_slice, \n",
    "                                    save_path=f\"{save_path}/D_eigenvals_H_{H_slice}.pdf\", \n",
    "                                )\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    O_eigenvals, \n",
    "                                    matrix_id=\"O\", \n",
    "                                    n_hidden_slice=H_slice, \n",
    "                                    save_path=f\"{save_path}/O_eigenvals_H_{H_slice}.pdf\", \n",
    "                                )\n",
    "        \n",
    "                                # H theory slices\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    H_theory_eigenvals, \n",
    "                                    matrix_id=\"H_{theory}\", \n",
    "                                    width_slice=N_slice, \n",
    "                                    save_path=f\"{save_path}/H_theory_eigenvals_N_{N_slice}.pdf\", \n",
    "                                )\n",
    "                                plot_hessian_eigenvalues_slice(\n",
    "                                    H_theory_eigenvals, \n",
    "                                    matrix_id=\"H_{theory}\", \n",
    "                                    n_hidden_slice=H_slice, \n",
    "                                    save_path=f\"{save_path}/H_theory_eigenvals_H_{H_slice}.pdf\", \n",
    "                                )\n",
    "                        \n",
    "                                # max & min eigens phase plots\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    D_max_eigen, \n",
    "                                    \"$\\lambda_{max}(D)$\", \n",
    "                                    f\"{save_path}/D_max_eigen.pdf\"\n",
    "                                )\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    O_max_eigen, \n",
    "                                    \"$\\lambda_{max}(O)$\", \n",
    "                                    f\"{save_path}/O_max_eigen.pdf\"\n",
    "                                )\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    H_theory_max_eigen, \n",
    "                                    \"$\\lambda_{max}(H_{theory})$\", \n",
    "                                    f\"{save_path}/H_theory_max_eigen.pdf\"\n",
    "                                )\n",
    "                        \n",
    "                                plot_metric_phase_diagram(\n",
    "                                    D_min_eigen, \n",
    "                                    \"$\\lambda_{min}(D)$\", \n",
    "                                    f\"{save_path}/D_min_eigen.pdf\"\n",
    "                                )\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    O_min_eigen, \n",
    "                                    \"$\\lambda_{min}(O)$\", \n",
    "                                    f\"{save_path}/O_min_eigen.pdf\"\n",
    "                                )\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    H_theory_min_eigen, \n",
    "                                    \"$\\lambda_{min}(H_{theory})$\", \n",
    "                                    f\"{save_path}/H_theory_min_eigen.pdf\"\n",
    "                                )\n",
    "                        \n",
    "                                # cond num phase plot\n",
    "                                plot_metric_phase_diagram(\n",
    "                                    H_theory_cond_num, \n",
    "                                    \"$\\kappa(H_{theory})$\", \n",
    "                                    f\"{save_path}/H_theory_cond_num.pdf\",\n",
    "                                    title=act_fn_title,\n",
    "                                    log=False if (not use_skips and param_type == \"sp\") else True\n",
    "                                )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Forward pass results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_per_iv(\n",
    "        metric, \n",
    "        metric_id, \n",
    "        ivs,\n",
    "        yaxis_title, \n",
    "        xaxis_title, \n",
    "        param_type, \n",
    "        save_path\n",
    "):\n",
    "    fig = go.Figure()\n",
    "    layer_idxs = [1, \"1/4L\", \"1/2L\", \"3/4L\", \"L\"]\n",
    "\n",
    "    n_layers = metric.shape[0]\n",
    "    colorscale = \"Reds\" if metric_id == \"activities\" else \"Greens\"\n",
    "    colors = pc.sample_colorscale(colorscale, n_layers + 3)[3:]\n",
    "    for i, layer_metric in enumerate(metric):\n",
    "        layer_idx = layer_idxs[i]\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=ivs,\n",
    "                y=layer_metric,\n",
    "                name=f\"$\\ell = {{{layer_idx}}}$\",\n",
    "                mode=\"lines\" if (\n",
    "                    xaxis_title == \"Training iteration\"\n",
    "                ) else \"lines+markers\",\n",
    "                line=dict(width=2, color=colors[i]),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        width=550,\n",
    "        xaxis=dict(title=xaxis_title),\n",
    "        yaxis=dict(title=yaxis_title),\n",
    "        font=dict(size=18),\n",
    "        margin=dict(r=140, b=90, l=110)\n",
    "    )\n",
    "    if metric_id == \"activities\" and param_type == \"sp\":\n",
    "        fig.update_layout(\n",
    "            yaxis=dict(\n",
    "                type=\"log\",\n",
    "                exponentformat=\"power\",\n",
    "                dtick=10 if xaxis_title == \"Depth\" else 1\n",
    "            )\n",
    "        )            \n",
    "    if xaxis_title != \"Training iteration\":\n",
    "        fig.update_layout(\n",
    "            xaxis=dict(\n",
    "                tickvals=ivs,\n",
    "                ticktext=[f\"$\\\\large{{2^{{{int(np.log2(iv))}}}}}$\" for iv in ivs],\n",
    "                type=\"log\",\n",
    "                exponentformat=\"power\"\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(\n",
    "            xaxis=dict(\n",
    "                tickvals=[0, int(ivs[-1]/2), ivs[-1]],\n",
    "                ticktext=[0, int(ivs[-1]/2), ivs[-1]]\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    fig.write_image(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"mlp_fwd_pass_results\"\n",
    "widths = [2 ** i for i in range(7, 11)]\n",
    "depths = [2 **  i for i in range(4, 10)]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "optim_ids = [\"sgd\", \"adam\"]\n",
    "param_types = [\"sp\", \"depth_mup\", \"orthogonal\"]\n",
    "seed = 54638\n",
    "n_ts = 3\n",
    "\n",
    "for act_fn in act_fns:\n",
    "    for optim_id in optim_ids:\n",
    "        for param_type in param_types:\n",
    "\n",
    "            skip_uses = [False, True] if param_type != \"orthogonal\" else [False]\n",
    "            for use_skips in skip_uses:\n",
    "                save_dir = os.path.join(\n",
    "                    RESULTS_DIR,\n",
    "                    act_fn,\n",
    "                    optim_id,\n",
    "                    param_type,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                avg_activity_l1_per_N_L = np.load(f\"{save_dir}/avg_activity_l1_per_N_L.npy\")\n",
    "                avg_activity_l2_per_N_L = np.load(f\"{save_dir}/avg_activity_l2_per_N_L.npy\")\n",
    "                param_l2_norms_per_N_L = np.load(f\"{save_dir}/param_l2_norms_per_N_L.npy\")\n",
    "                param_spectral_norms_per_N_L = np.load(f\"{save_dir}/param_spectral_norms_per_N_L.npy\")\n",
    "        \n",
    "                # activities l1 norm vs width & depth\n",
    "                width_idxs = [0, -1]  # 128 & 1024 units\n",
    "                depth_idx = 0   # 16 layers\n",
    "                L = depths[depth_idx]\n",
    "                for t in range(n_ts):\n",
    "                    plot_metric_per_iv(\n",
    "                        metric=avg_activity_l1_per_N_L[:, t, :, depth_idx],\n",
    "                        metric_id=\"activities\", \n",
    "                        ivs=widths,\n",
    "                        yaxis_title=\"$\\Large{||\\mathbf{z}_\\ell||_1}$\", \n",
    "                        xaxis_title=\"Width\",\n",
    "                        param_type=param_type,\n",
    "                        save_path=f\"{save_dir}/avg_activity_l1_per_N_at_t{t}_L_{L}.pdf\"\n",
    "                    )\n",
    "                    for width_idx in width_idxs:\n",
    "                        N = widths[width_idx]\n",
    "                        plot_metric_per_iv(\n",
    "                            metric=avg_activity_l1_per_N_L[:, t, width_idx, :],\n",
    "                            metric_id=\"activities\", \n",
    "                            ivs=depths,\n",
    "                            yaxis_title=\"$\\Large{||\\mathbf{z}_\\ell||_1}$\", \n",
    "                            xaxis_title=\"Depth\",\n",
    "                            param_type=param_type,\n",
    "                            save_path=f\"{save_dir}/avg_activity_l1_per_L_at_t{t}_N_{N}.pdf\"\n",
    "                        )\n",
    "    \n",
    "                # activities l2 norm vs width & depth\n",
    "                for t in range(n_ts):\n",
    "                    plot_metric_per_iv(\n",
    "                        metric=avg_activity_l2_per_N_L[:, t, :, depth_idx],\n",
    "                        metric_id=\"activities\", \n",
    "                        ivs=widths,\n",
    "                        yaxis_title=\"$\\Large{||\\mathbf{z}_\\ell||_2}$\", \n",
    "                        xaxis_title=\"Width\",\n",
    "                        param_type=param_type,\n",
    "                        save_path=f\"{save_dir}/avg_activity_l2_per_N_at_t{t}_L_{L}.pdf\"\n",
    "                    )\n",
    "                    for width_idx in width_idxs:\n",
    "                        N = widths[width_idx]\n",
    "                        plot_metric_per_iv(\n",
    "                            metric=avg_activity_l2_per_N_L[:, t, width_idx, :],\n",
    "                            metric_id=\"activities\", \n",
    "                            ivs=depths,\n",
    "                            yaxis_title=\"$\\Large{||\\mathbf{z}_\\ell||_2}$\", \n",
    "                            xaxis_title=\"Depth\",\n",
    "                            param_type=param_type,\n",
    "                            save_path=f\"{save_dir}/avg_activity_l2_per_L_at_t{t}_N_{N}.pdf\"\n",
    "                        )\n",
    "    \n",
    "                # spectral params vs width & depth\n",
    "                for t in range(n_ts):\n",
    "                    plot_metric_per_iv(\n",
    "                        metric=param_spectral_norms_per_N_L[:, t, :, depth_idx],\n",
    "                        metric_id=\"params\", \n",
    "                        ivs=widths,\n",
    "                        yaxis_title=\"$\\Large{||W_\\ell||_2}$\", \n",
    "                        xaxis_title=\"Width\", \n",
    "                        param_type=param_type,\n",
    "                        save_path=f\"{save_dir}/params_spectral_norm_per_N_at_t{t}_L_{L}.pdf\"\n",
    "                    )\n",
    "                    for width_idx in width_idxs:\n",
    "                        N = widths[width_idx]\n",
    "                        plot_metric_per_iv(\n",
    "                            metric=param_spectral_norms_per_N_L[:, t, width_idx, :],\n",
    "                            metric_id=\"params\", \n",
    "                            ivs=depths,\n",
    "                            yaxis_title=\"$\\Large{||W_\\ell||_2}$\", \n",
    "                            xaxis_title=\"Depth\",\n",
    "                            param_type=param_type,\n",
    "                            save_path=f\"{save_dir}/params_spectral_norm_per_L_at_t{t}_N_{N}.pdf\"\n",
    "                        )\n",
    "    \n",
    "                # spectral params over training\n",
    "                n_train_iters = param_spectral_norms_per_N_L.shape[1]\n",
    "                for width_idx in width_idxs:\n",
    "                    N = widths[width_idx]\n",
    "                    plot_metric_per_iv(\n",
    "                        metric=param_spectral_norms_per_N_L[:, :, width_idx, depth_idx],\n",
    "                        metric_id=\"params\", \n",
    "                        ivs=[t for t in range(n_train_iters)],\n",
    "                        yaxis_title=\"$\\Large{||W_\\ell||_2}$\",\n",
    "                        xaxis_title=\"Training iteration\", \n",
    "                        param_type=param_type,\n",
    "                        save_path=f\"{save_dir}/params_spectral_norm_over_t_N_{N}.pdf\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_cond_num, compute_metric_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_per_iv(metric, metric_id, iv_id, test_every, save_path, height=300, width=450):\n",
    "    key = next(iter(metric))\n",
    "    n_iters = len(metric[key][0])\n",
    "    iters = [t for t in range(n_iters)]\n",
    "    ivs = metric.keys()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    if metric_id == \"cond_num\":\n",
    "        colorscale = \"Viridis\"\n",
    "        colors = pc.sample_colorscale(colorscale, len(ivs)) \n",
    "    elif metric_id == \"test_acc\":\n",
    "        if iv_id == \"n_hidden\":\n",
    "            colorscale = \"Blues\" \n",
    "        elif iv_id == \"width\":\n",
    "            colorscale = \"Reds\" \n",
    "        else:\n",
    "            colorscale = \"Oranges\"\n",
    "        colors = pc.sample_colorscale(colorscale, len(ivs)+2)[2:]\n",
    "        \n",
    "    for iv, color in zip(ivs, colors):\n",
    "        means, stds = metric[iv][0], metric[iv][1]\n",
    "        y_upper, y_lower = means + stds, means - stds\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=list(iters) + list(iters[::-1]),\n",
    "                y=list(y_upper) + list(y_lower[::-1]),\n",
    "                fill=\"toself\",\n",
    "                fillcolor=color,\n",
    "                line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "                opacity=0.3\n",
    "            )\n",
    "        )\n",
    "        if iv == 8:\n",
    "            label = \"2^3\"\n",
    "        elif iv == 16:\n",
    "            label = \"2^4\"\n",
    "        elif iv == 32:\n",
    "            label = \"2^5\"\n",
    "        elif iv == 64:\n",
    "            label = \"2^6\"\n",
    "        elif iv == 128:\n",
    "            label = \"2^7\"\n",
    "        elif iv == 256:\n",
    "            label = \"2^8\"\n",
    "        elif iv == 512:\n",
    "            label = \"2^9\"\n",
    "        elif iv == 1024:\n",
    "            label = \"2^{10}\"\n",
    "\n",
    "        elif iv == 1000:\n",
    "            label = \"1e^3\"\n",
    "        elif iv == 500:\n",
    "            label = \"5e^2\"\n",
    "        elif iv == 100:\n",
    "            label = \"1e^2\"\n",
    "        elif iv == 50:\n",
    "            label = \"5e^1\"\n",
    "        elif iv == 10:\n",
    "            label = \"1e^1\"\n",
    "        elif iv == 5:\n",
    "            label = \"5e^0\"\n",
    "        elif iv == 1:\n",
    "            label = \"1e^0\"\n",
    "        elif iv == 5e-1:\n",
    "            label = \"5e^{-1}\"\n",
    "        elif iv == 1e-1:\n",
    "            label = \"1e^{-1}\"\n",
    "        elif iv == 5e-2:\n",
    "            label = \"5e^{-2}\"\n",
    "        elif iv == 1e-2:\n",
    "            label = \"1e^{-2}\"\n",
    "        elif iv == 5e-3:\n",
    "            label = \"5e^{-3}\"\n",
    "        elif iv == 1e-3:\n",
    "            label = \"1e^{-3}\"\n",
    "        elif iv == 5e-4:\n",
    "            label = \"5e^{-4}\"\n",
    "        elif iv == 1e-4:\n",
    "            label = \"1e^{-4}\"\n",
    "\n",
    "        if iv_id == \"n_hidden\":\n",
    "            iv_label = \"H\" \n",
    "        elif iv_id == \"width\":\n",
    "            iv_label = \"N\" \n",
    "        else:\n",
    "            iv_label = \"\\eta\"\n",
    "            \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=iters,\n",
    "                y=means,\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(width=2, color=color),\n",
    "                name=f\"${iv_label}={label}$\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    xtickvals = [0, int(iters[-1] / 2), iters[-1]]\n",
    "    if metric_id == \"test_acc\":\n",
    "        xticktext = [(t+1) * test_every for t in xtickvals]\n",
    "        yaxis_title = \"Test accuracy (%)\"\n",
    "    else:\n",
    "        xticktext = [t * test_every for t in xtickvals]\n",
    "        yaxis_title = \"$\\Large{\\kappa(\\mathrm{H}_{\\mathbf{z}})}$\"\n",
    "        \n",
    "    fig.update_layout(\n",
    "        height=height,\n",
    "        width=width,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\",\n",
    "            tickvals=xtickvals,\n",
    "            ticktext=xticktext\n",
    "        ),\n",
    "        yaxis=dict(title=yaxis_title),\n",
    "        font=dict(size=16),\n",
    "        margin=dict(r=120 if iv_id != \"activity_lr\" else 130)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ GD learning rate sweep ############\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "n_hiddens = [8, 16, 32]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lrs = [5e-1, 1e-1, 5e-2]\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        for n_hidden in n_hiddens:\n",
    "\n",
    "            test_accs_per_H = {} \n",
    "            for activity_lr in activity_lrs:\n",
    "                test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"skips\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                    test_accs_all_seeds[seed] = test_accs\n",
    "    \n",
    "                test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)                \n",
    "                test_accs_per_H[activity_lr] = (test_acc_means, test_acc_stds)\n",
    "    \n",
    "            plot_metric_per_iv(\n",
    "                metric=test_accs_per_H,\n",
    "                metric_id=\"test_acc\", \n",
    "                iv_id=\"activity_lr\",\n",
    "                test_every=test_every, \n",
    "                save_path=f\"{results_dir}/{dataset}/test_accs_GD_{act_fn}_{n_hidden}_n_hidden.pdf\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best GD results ############\n",
    "n_hiddens = [8, 16, 32]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        \n",
    "        test_accs_per_H = {} \n",
    "        cond_nums_per_H = {} \n",
    "        for n_hidden in n_hiddens:\n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "            cond_nums_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on dataset, act fn & n hidden\n",
    "            if dataset == \"MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "\n",
    "            elif dataset == \"Fashion-MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                hessian_eigenvals = np.load(f\"{save_path}/hessian_eigenvals.npy\")\n",
    "                cond_nums = [compute_cond_num(eig) for eig in hessian_eigenvals]\n",
    "                \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "                cond_nums_all_seeds[seed] = cond_nums\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            cond_num_means, cond_num_stds = compute_metric_stats(cond_nums_all_seeds)\n",
    "            \n",
    "            test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "            cond_nums_per_H[n_hidden] = (cond_num_means, cond_num_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_H,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_GD_{act_fn}.pdf\"\n",
    "        )\n",
    "        plot_metric_per_iv(\n",
    "            metric=cond_nums_per_H, \n",
    "            metric_id=\"cond_num\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_cond_nums_GD_{act_fn}.pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Adam learning rate sweep ############\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "n_hiddens = [8, 16, 32]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"adam\"\n",
    "activity_lrs = [5e-1, 1e-1, 5e-2]\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        for n_hidden in n_hiddens:\n",
    "\n",
    "            test_accs_per_H = {} \n",
    "            for activity_lr in activity_lrs:\n",
    "                test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"skips\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                    test_accs_all_seeds[seed] = test_accs\n",
    "    \n",
    "                test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)                \n",
    "                test_accs_per_H[activity_lr] = (test_acc_means, test_acc_stds)\n",
    "    \n",
    "            plot_metric_per_iv(\n",
    "                metric=test_accs_per_H,\n",
    "                metric_id=\"test_acc\", \n",
    "                iv_id=\"activity_lr\",\n",
    "                test_every=test_every, \n",
    "                save_path=f\"{results_dir}/{dataset}/test_accs_Adam_{act_fn}_{n_hidden}_n_hidden.pdf\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best Adam results ############\n",
    "n_hiddens = [8, 16, 32]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"adam\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        \n",
    "        test_accs_per_H = {} \n",
    "        cond_nums_per_H = {} \n",
    "        for n_hidden in n_hiddens:\n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "            cond_nums_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on dataset, act fn & n hidden\n",
    "            if dataset == \"MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "\n",
    "            elif dataset == \"Fashion-MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                hessian_eigenvals = np.load(f\"{save_path}/hessian_eigenvals.npy\")\n",
    "                cond_nums = [compute_cond_num(eig) for eig in hessian_eigenvals]\n",
    "                \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "                cond_nums_all_seeds[seed] = cond_nums\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            cond_num_means, cond_num_stds = compute_metric_stats(cond_nums_all_seeds)\n",
    "            \n",
    "            test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "            cond_nums_per_H[n_hidden] = (cond_num_means, cond_num_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_H,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_Adam_{act_fn}.pdf\"\n",
    "        )\n",
    "        plot_metric_per_iv(\n",
    "            metric=cond_nums_per_H, \n",
    "            metric_id=\"cond_num\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_cond_nums_Adam_{act_fn}.pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ skip learning rate sweep ############\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "n_hiddens = [8, 16, 32]\n",
    "width = 128\n",
    "use_skips = True\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lrs = [5e-1, 1e-1, 5e-2]\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        for n_hidden in n_hiddens:\n",
    "\n",
    "            test_accs_per_H = {} \n",
    "            for activity_lr in activity_lrs:\n",
    "                test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"skips\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                    test_accs_all_seeds[seed] = test_accs\n",
    "    \n",
    "                test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)                \n",
    "                test_accs_per_H[activity_lr] = (test_acc_means, test_acc_stds)\n",
    "    \n",
    "            plot_metric_per_iv(\n",
    "                metric=test_accs_per_H,\n",
    "                metric_id=\"test_acc\", \n",
    "                iv_id=\"activity_lr\",\n",
    "                test_every=test_every, \n",
    "                save_path=f\"{results_dir}/{dataset}/test_accs_GD_{act_fn}_{n_hidden}_n_hidden_skips.pdf\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best skips results ############\n",
    "n_hiddens = [8, 16, 32]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "width = 128\n",
    "use_skips = True\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        \n",
    "        test_accs_per_H = {} \n",
    "        cond_nums_per_H = {} \n",
    "        for n_hidden in n_hiddens:\n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "            cond_nums_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on dataset, act fn & n hidden\n",
    "            if dataset == \"MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "\n",
    "            elif dataset == \"Fashion-MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-1\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                hessian_eigenvals = np.load(f\"{save_path}/hessian_eigenvals.npy\")\n",
    "                cond_nums = [compute_cond_num(eig) for eig in hessian_eigenvals]\n",
    "                \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "                cond_nums_all_seeds[seed] = cond_nums\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            cond_num_means, cond_num_stds = compute_metric_stats(cond_nums_all_seeds)\n",
    "            \n",
    "            test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "            cond_nums_per_H[n_hidden] = (cond_num_means, cond_num_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_H,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_GD_skips_{act_fn}.pdf\"\n",
    "        )\n",
    "        plot_metric_per_iv(\n",
    "            metric=cond_nums_per_H, \n",
    "            metric_id=\"cond_num\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_cond_nums_GD_skips_{act_fn}.pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Orthogonal init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ orthogonal init. learning rate sweep ############\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"orthogonal\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lrs = [5e-1, 1e-1, 5e-2]\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        n_hiddens = [8, 16, 32, 64, 128] if (\n",
    "            act_fn != \"relu\" \n",
    "        ) else [8, 16, 32]\n",
    "        \n",
    "        for n_hidden in n_hiddens:\n",
    "\n",
    "            test_accs_per_H = {} \n",
    "            for activity_lr in activity_lrs:\n",
    "                test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"skips\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                    test_accs_all_seeds[seed] = test_accs\n",
    "                    \n",
    "                test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "                test_accs_per_H[activity_lr] = (test_acc_means, test_acc_stds)\n",
    "\n",
    "            plot_metric_per_iv(\n",
    "                metric=test_accs_per_H,\n",
    "                metric_id=\"test_acc\", \n",
    "                iv_id=\"activity_lr\",\n",
    "                test_every=test_every, \n",
    "                save_path=f\"{results_dir}/{dataset}/test_accs_orthogonal_{act_fn}_{n_hidden}_n_hidden.pdf\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best orthogonal init. results ############\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\"]\n",
    "width = 128\n",
    "use_skips = False\n",
    "weight_init = \"orthogonal\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-3\n",
    "batch_size = 64\n",
    "max_infer_iters = 500\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        n_hiddens = [8, 16, 32, 64, 128] if (\n",
    "            act_fn != \"relu\" \n",
    "        ) else [8, 16, 32]\n",
    "        \n",
    "        test_accs_per_H = {} \n",
    "        cond_nums_per_H = {} \n",
    "        for n_hidden in n_hiddens:\n",
    "            compute_hessian = False if (\n",
    "                dataset == \"Fashion-MNIST\" and act_fn == \"tanh\" and n_hidden == 128\n",
    "            ) else True\n",
    "            \n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "            cond_nums_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on dataset, act fn & n hidden\n",
    "            if dataset == \"MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 64:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 128:\n",
    "                        activity_lr = 1e-1\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 64:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 128:\n",
    "                        activity_lr = 5e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "\n",
    "            elif dataset == \"Fashion-MNIST\":\n",
    "                if act_fn == \"linear\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 64:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 128:\n",
    "                        activity_lr = 5e-2\n",
    "                \n",
    "                elif act_fn == \"tanh\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 64:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 128:\n",
    "                        activity_lr = 5e-1\n",
    "    \n",
    "                elif act_fn == \"relu\":\n",
    "                    if n_hidden == 8:\n",
    "                        activity_lr = 1e-1\n",
    "                    elif n_hidden == 16:\n",
    "                        activity_lr = 5e-2\n",
    "                    elif n_hidden == 32:\n",
    "                        activity_lr = 5e-2\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                if compute_hessian:\n",
    "                    hessian_eigenvals = np.load(f\"{save_path}/hessian_eigenvals.npy\")\n",
    "                    cond_nums = [compute_cond_num(eig) for eig in hessian_eigenvals]\n",
    "                \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "                if compute_hessian:\n",
    "                    cond_nums_all_seeds[seed] = cond_nums\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            if compute_hessian:\n",
    "                cond_num_means, cond_num_stds = compute_metric_stats(cond_nums_all_seeds)\n",
    "            \n",
    "            test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "            if compute_hessian:\n",
    "                cond_nums_per_H[n_hidden] = (cond_num_means, cond_num_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_H,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_orthogonal_{act_fn}.pdf\"\n",
    "        )\n",
    "        plot_metric_per_iv(\n",
    "            metric=cond_nums_per_H, \n",
    "            metric_id=\"cond_num\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_cond_nums_orthogonal_{act_fn}.pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### $\\mu$PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_metric_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mupc_vs_pc_vs_bp_accs(\n",
    "        mupc_accs, \n",
    "        pc_accs,\n",
    "        bp_accs, \n",
    "        test_every, \n",
    "        act_fn, \n",
    "        save_path, \n",
    "        height=300, \n",
    "        width=450,\n",
    "        show_bp=True,\n",
    "        show_pc=True,\n",
    "        show_mupc=True,\n",
    "    ):\n",
    "    key = next(iter(mupc_accs))\n",
    "    n_iters = len(mupc_accs[key][0])\n",
    "    iters = [t for t in range(n_iters)]\n",
    "    ivs = mupc_accs.keys()\n",
    "\n",
    "    mupc_colors = pc.sample_colorscale(\"Blues\", len(ivs)+2)[1:]\n",
    "    pc_colors = pc.sample_colorscale(\"Reds\", len(ivs)+2)[2:]\n",
    "    bp_color = \"black\"\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i, iv in enumerate(ivs):\n",
    "        mupc_means, mupc_stds = mupc_accs[iv][0], mupc_accs[iv][1]\n",
    "        pc_means, pc_stds = pc_accs[iv][0], pc_accs[iv][1]\n",
    "        \n",
    "        mupc_y_upper, mupc_y_lower = mupc_means + mupc_stds, mupc_means - mupc_stds\n",
    "        pc_y_upper, pc_y_lower = pc_means + pc_stds, pc_means - pc_stds\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=list(iters) + list(iters[::-1]),\n",
    "                y=list(mupc_y_upper) + list(mupc_y_lower[::-1]),\n",
    "                fill=\"toself\",\n",
    "                fillcolor=mupc_colors[i],\n",
    "                line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "                opacity=0.3 if show_mupc else 0\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=list(iters) + list(iters[::-1]),\n",
    "                y=list(pc_y_upper) + list(pc_y_lower[::-1]),\n",
    "                fill=\"toself\",\n",
    "                fillcolor=pc_colors[i],\n",
    "                line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "                opacity=0.3 if show_pc else 0\n",
    "            )\n",
    "        )  \n",
    "        if iv == 8:\n",
    "            label = \"2^3\"\n",
    "        elif iv == 16:\n",
    "            label = \"2^4\"\n",
    "        elif iv == 32:\n",
    "            label = \"2^5\"\n",
    "        elif iv == 64:\n",
    "            label = \"2^6\"\n",
    "        elif iv == 128:\n",
    "            label = \"2^7\"\n",
    "\n",
    "        if iv == 128:\n",
    "            bp_means, bp_stds = bp_accs[iv][0], bp_accs[iv][1]\n",
    "            bp_y_upper, bp_y_lower = bp_means + bp_stds, bp_means - bp_stds\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=list(iters) + list(iters[::-1]),\n",
    "                    y=list(bp_y_upper) + list(bp_y_lower[::-1]),\n",
    "                    fill=\"toself\",\n",
    "                    fillcolor=bp_color,\n",
    "                    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "                    hoverinfo=\"skip\",\n",
    "                    showlegend=False,\n",
    "                    opacity=0.3 if show_bp else 0\n",
    "                )\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=iters,\n",
    "                    y=bp_means,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=3, color=bp_color, dash=\"dash\"),\n",
    "                    showlegend=False,\n",
    "                    opacity=1 if show_bp else 0\n",
    "                )\n",
    "            )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=iters,\n",
    "                y=mupc_means,\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(width=2, color=mupc_colors[i]),\n",
    "                showlegend=False,\n",
    "                opacity=1 if show_mupc else 0\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=iters,\n",
    "                y=pc_means,\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(width=2, color=pc_colors[i], dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "                opacity=1 if show_pc else 0\n",
    "            )\n",
    "        )\n",
    "\n",
    "    xtickvals = [0, int(iters[-1] / 2), iters[-1]]\n",
    "    xticktext = [(t+1) * test_every for t in xtickvals]\n",
    "\n",
    "    if act_fn == \"relu\":\n",
    "        ytickvals = [10, 50, 90]\n",
    "    elif act_fn == \"tanh\":\n",
    "        ytickvals = [60, 75, 90]\n",
    "    elif act_fn == \"linear\":\n",
    "        ytickvals = [10, 30, 50, 70, 90]\n",
    "    \n",
    "    yticktext = ytickvals\n",
    "    fig.update_layout(\n",
    "        height=height,\n",
    "        width=width,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\",\n",
    "            tickvals=xtickvals,\n",
    "            ticktext=xticktext\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Test accuracy (%)\",\n",
    "            tickvals=ytickvals,\n",
    "            ticktext=yticktext\n",
    "        ),\n",
    "        font=dict(size=16),\n",
    "        margin=dict(r=120)\n",
    "    )\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def create_legend(n_hiddens, save_path, colorscale=\"Blues\", starting_color=1, marker_size=5, fontsize=8, height=50, width=500):\n",
    "    colors = pc.sample_colorscale(colorscale, len(n_hiddens)+2)[starting_color:]\n",
    "\n",
    "    if \"Blues\" in colorscale:\n",
    "        dash = \"solid\"\n",
    "    elif \"Reds\" in colorscale:\n",
    "        dash = \"dash\"\n",
    "    else:\n",
    "        dash = \"dash\"\n",
    "        \n",
    "    traces = [\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode=\"lines\" if \"gray\" in colorscale else \"lines+markers\",\n",
    "            line=dict(\n",
    "                width=2, \n",
    "                color=color, \n",
    "                dash=dash\n",
    "            ),\n",
    "            marker=dict(\n",
    "                size=marker_size, \n",
    "                color=color,\n",
    "                #symbol=\"diamond\" if \"Reds\" in colorscale else \"circle\"\n",
    "            ),\n",
    "            name=f\"$H={h}$\"\n",
    "        )\n",
    "        for h, color in zip(n_hiddens, colors)\n",
    "    ]\n",
    "    fig = go.Figure(data=traces)    \n",
    "    fig.update_layout(\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.0,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(size=fontsize)\n",
    "        ),\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Condition numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ cond numers of muPC results for depth at fixed width N = 512 ############\n",
    "n_hiddens = [8, 16, 32]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "width = 512\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-1  # 5e-2 for Fashion - based on transfer results below\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lr = 5e-1\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "for act_fn in act_fns:\n",
    "    \n",
    "    cond_nums_per_H = {} \n",
    "    for n_hidden in n_hiddens:\n",
    "        max_infer_iters = n_hidden\n",
    "        \n",
    "        cond_nums_all_seeds = [[] for seed in range(n_seeds)]\n",
    "        for seed in range(n_seeds):\n",
    "        \n",
    "            save_path = os.path.join(\n",
    "                results_dir,\n",
    "                dataset,\n",
    "                f\"width_{width}\",\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                act_fn,\n",
    "                \"skips\" if use_skips else \"no_skips\",\n",
    "                f\"{weight_init}_weight_init\",\n",
    "                f\"{param_type}_param\",\n",
    "                f\"param_optim_{param_optim_id}\",\n",
    "                f\"param_lr_{param_lr}\",\n",
    "                f\"batch_size_{batch_size}\",\n",
    "                f\"{max_infer_iters}_max_infer_iters\",\n",
    "                f\"activity_optim_{activity_optim_id}\",\n",
    "                f\"activity_lr_{activity_lr}\",\n",
    "                f\"activity_decay_{activity_decay}\",\n",
    "                f\"weight_decay_{weight_decay}\",\n",
    "                f\"spectral_penalty_{spectral_penalty}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            hessian_eigenvals = np.load(f\"{save_path}/hessian_eigenvals.npy\")\n",
    "            cond_nums = [compute_cond_num(eig) for eig in hessian_eigenvals]                \n",
    "            cond_nums_all_seeds[seed] = cond_nums\n",
    "\n",
    "        cond_nums_means, cond_nums_stds = compute_metric_stats(cond_nums_all_seeds)\n",
    "        cond_nums_per_H[n_hidden] = (cond_nums_means, cond_nums_stds)\n",
    "\n",
    "    plot_metric_per_iv(\n",
    "        metric=cond_nums_per_H, \n",
    "        metric_id=\"cond_num\", \n",
    "        iv_id=\"n_hidden\",\n",
    "        test_every=test_every, \n",
    "        save_path=f\"{results_dir}/{dataset}/best_cond_nums_mupc_{act_fn}.pdf\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Lr sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ muPC learning rate sweep ############\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\"]\n",
    "\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "width = 512\n",
    "n_hiddens = [2**i for i in range(3, 8)]\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-1  # NOTE: best based on transfer results below\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lrs = [1000, 500, 100, 50, 10, 5, 1, 5e-1, 1e-1, 5e-2, 1e-2]\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns: \n",
    "        for n_hidden in n_hiddens:\n",
    "            max_infer_iters = n_hidden\n",
    "\n",
    "            test_accs_per_H = {} \n",
    "            for activity_lr in activity_lrs:\n",
    "                test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"skips\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "                    # fill NA accuracy with chance performance \n",
    "                    if len(test_accs) == 0:\n",
    "                        test_accs = [10]\n",
    "                        \n",
    "                    test_accs_all_seeds[seed] = test_accs\n",
    "                    \n",
    "                test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "                test_accs_per_H[activity_lr] = (test_acc_means, test_acc_stds)\n",
    "            \n",
    "            plot_metric_per_iv(\n",
    "                metric=test_accs_per_H,\n",
    "                metric_id=\"test_acc\", \n",
    "                iv_id=\"activity_lr\",\n",
    "                test_every=test_every, \n",
    "                save_path=f\"{results_dir}/{dataset}/test_accs_muPC_{act_fn}_{n_hidden}_n_hidden.pdf\",\n",
    "                height=450,\n",
    "                width=650\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Width (wider is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best muPC results for width at fixed depth H = 8 ############\n",
    "widths = [64, 128, 256, 512, 1024]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\"]\n",
    "n_hidden = 8\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-1\n",
    "batch_size = 64\n",
    "max_infer_iters = 8\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        \n",
    "        test_accs_per_N = {} \n",
    "        for width in widths:\n",
    "            \n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on act\n",
    "            if act_fn == \"linear\":\n",
    "                activity_lr = 1\n",
    "            elif act_fn == \"tanh\":\n",
    "                activity_lr = 1\n",
    "            elif act_fn == \"relu\":\n",
    "                activity_lr = 5e-1\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\") \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            test_accs_per_N[width] = (test_acc_means, test_acc_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_N,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"width\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_width_muP_{act_fn}.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best muPC results for depth at fixed width N = 512 ############\n",
    "n_hiddens = [8, 16, 32, 64, 128]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "datasets = [\"MNIST\"]\n",
    "width = 512\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-1  # NOTE: best based on transfer results below\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    for act_fn in act_fns:\n",
    "        \n",
    "        test_accs_per_H = {} \n",
    "        for n_hidden in n_hiddens:\n",
    "            max_infer_iters = n_hidden\n",
    "            \n",
    "            test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "            # best lr based on act\n",
    "            if act_fn == \"linear\":\n",
    "                activity_lr = 1\n",
    "            elif act_fn == \"tanh\":\n",
    "                activity_lr = 1\n",
    "            elif act_fn == \"relu\":\n",
    "                activity_lr = 5e-1\n",
    "            \n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\") \n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "\n",
    "            test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "            test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "\n",
    "        plot_metric_per_iv(\n",
    "            metric=test_accs_per_H,\n",
    "            metric_id=\"test_acc\", \n",
    "            iv_id=\"n_hidden\",\n",
    "            test_every=test_every, \n",
    "            save_path=f\"{results_dir}/{dataset}/best_test_accs_depth_muP_{act_fn}.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### MNIST results after 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "act_fn = \"relu\"\n",
    "width = 512\n",
    "n_hidden = 128\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 1e-1\n",
    "batch_size = 64\n",
    "max_infer_iters = 128\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lr = 5e-1\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 5\n",
    "test_every = 300\n",
    "n_seeds = 5\n",
    "\n",
    "test_accs_all_seeds = [[] for _ in range(n_seeds)]\n",
    "for seed in range(n_seeds):\n",
    "    save_path = os.path.join(\n",
    "        results_dir,\n",
    "        dataset,\n",
    "        f\"width_{width}\",\n",
    "        f\"{n_hidden}_n_hidden\",\n",
    "        act_fn,\n",
    "        \"skips\" if use_skips else \"no_skips\",\n",
    "        f\"{weight_init}_weight_init\",\n",
    "        f\"{param_type}_param\",\n",
    "        f\"param_optim_{param_optim_id}\",\n",
    "        f\"param_lr_{param_lr}\",\n",
    "        f\"batch_size_{batch_size}\",\n",
    "        f\"{max_infer_iters}_max_infer_iters\",\n",
    "        f\"activity_optim_{activity_optim_id}\",\n",
    "        f\"activity_lr_{activity_lr}\",\n",
    "        f\"activity_decay_{activity_decay}\",\n",
    "        f\"weight_decay_{weight_decay}\",\n",
    "        f\"spectral_penalty_{spectral_penalty}\",\n",
    "        f\"{max_epochs}_epochs\",\n",
    "        str(seed)\n",
    "    )\n",
    "    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "    # fill NA accuracy with chance performance \n",
    "    if len(test_accs) == 0:\n",
    "        test_accs = [10]\n",
    "\n",
    "    test_accs_all_seeds[seed] = test_accs\n",
    "\n",
    "plot_metric_stats(\n",
    "    metric=test_accs_all_seeds, \n",
    "    metric_id=\"test_acc\",\n",
    "    test_every=test_every, \n",
    "    save_path=f\"{results_dir}/mupc_128_MNIST_acc_5_epochs.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fashion-MNIST results after 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"pcn_results\"\n",
    "dataset = \"Fashion-MNIST\"\n",
    "act_fn = \"relu\"\n",
    "width = 512\n",
    "n_hidden = 128\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "param_lr = 5e-2\n",
    "batch_size = 64\n",
    "max_infer_iters = 128\n",
    "activity_optim_id = \"gd\"\n",
    "activity_lr = 5e-1\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 15\n",
    "test_every = 900\n",
    "n_seeds = 3\n",
    "\n",
    "test_accs_all_seeds = [[] for _ in range(n_seeds)]\n",
    "for seed in range(n_seeds):\n",
    "    save_path = os.path.join(\n",
    "        results_dir,\n",
    "        dataset,\n",
    "        f\"width_{width}\",\n",
    "        f\"{n_hidden}_n_hidden\",\n",
    "        act_fn,\n",
    "        \"skips\" if use_skips else \"no_skips\",\n",
    "        f\"{weight_init}_weight_init\",\n",
    "        f\"{param_type}_param\",\n",
    "        f\"param_optim_{param_optim_id}\",\n",
    "        f\"param_lr_{param_lr}\",\n",
    "        f\"batch_size_{batch_size}\",\n",
    "        f\"{max_infer_iters}_max_infer_iters\",\n",
    "        f\"activity_optim_{activity_optim_id}\",\n",
    "        f\"activity_lr_{activity_lr}\",\n",
    "        f\"activity_decay_{activity_decay}\",\n",
    "        f\"weight_decay_{weight_decay}\",\n",
    "        f\"spectral_penalty_{spectral_penalty}\",\n",
    "        f\"{max_epochs}_epochs\",\n",
    "        str(seed)\n",
    "    )\n",
    "    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "    test_accs_all_seeds[seed] = test_accs\n",
    "\n",
    "plot_metric_stats(\n",
    "    metric=test_accs_all_seeds, \n",
    "    metric_id=\"test_acc\",\n",
    "    test_every=test_every, \n",
    "    save_path=f\"{results_dir}/mupc_128_Fashion_acc_15_epochs.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Main figure for $\\mu$PC vs PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ muPC vs PC vs BP with Depth-muP ############\n",
    "n_hiddens = [8, 16, 32, 64, 128]\n",
    "act_fns = [\"relu\"]  #\"linear\", \"tanh\", \n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "width = 512\n",
    "use_skips = True\n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "for act_fn in act_fns:\n",
    "\n",
    "    bp_test_accs_per_H = {}\n",
    "    pc_test_accs_per_H = {}\n",
    "    mupc_test_accs_per_H = {} \n",
    "    for n_hidden in n_hiddens:\n",
    "        max_infer_iters = n_hidden\n",
    "        \n",
    "        bp_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "        pc_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "        mupc_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "        # muPC: best lrs based on act\n",
    "        mupc_param_lr = 1e-1\n",
    "        if act_fn == \"linear\":\n",
    "            mupc_activity_lr = 1\n",
    "        elif act_fn == \"tanh\":\n",
    "            mupc_activity_lr = 1\n",
    "        elif act_fn == \"relu\":\n",
    "            mupc_activity_lr = 5e-1\n",
    "\n",
    "        # PC: best lrs based on act & H\n",
    "        if act_fn == \"linear\":\n",
    "            pc_param_lr = 1e-2\n",
    "            pc_activity_lr = 1e-2\n",
    "        \n",
    "        elif act_fn == \"tanh\":\n",
    "            if n_hidden == 8:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-2\n",
    "            elif n_hidden == 16:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-2\n",
    "            elif n_hidden == 32:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-1\n",
    "            elif n_hidden == 64:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-1\n",
    "            elif n_hidden == 128:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-1\n",
    "        \n",
    "        elif act_fn == \"relu\":\n",
    "            if n_hidden == 8:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-1\n",
    "            elif n_hidden == 16:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-2\n",
    "            elif n_hidden == 32:\n",
    "                pc_param_lr = 1e-2\n",
    "                pc_activity_lr = 1e-2\n",
    "            elif n_hidden == 64:\n",
    "                pc_param_lr = 1e-1\n",
    "                pc_activity_lr = 1e-2\n",
    "        \n",
    "        for seed in range(n_seeds):\n",
    "        \n",
    "            pc_save_path = os.path.join(\n",
    "                results_dir,\n",
    "                dataset,\n",
    "                f\"width_{width}\",\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                act_fn,\n",
    "                \"skips\" if use_skips else \"no_skips\",\n",
    "                f\"standard_weight_init\",\n",
    "                f\"sp_param\",\n",
    "                f\"param_optim_{param_optim_id}\",\n",
    "                f\"param_lr_{pc_param_lr}\",\n",
    "                f\"batch_size_{batch_size}\",\n",
    "                f\"{max_infer_iters}_max_infer_iters\",\n",
    "                f\"activity_optim_{activity_optim_id}\",\n",
    "                f\"activity_lr_{pc_activity_lr}\",\n",
    "                f\"activity_decay_{activity_decay}\",\n",
    "                f\"weight_decay_{weight_decay}\",\n",
    "                f\"spectral_penalty_{spectral_penalty}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            mupc_save_path = os.path.join(\n",
    "                results_dir,\n",
    "                dataset,\n",
    "                f\"width_{width}\",\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                act_fn,\n",
    "                \"skips\" if use_skips else \"no_skips\",\n",
    "                f\"standard_gauss_weight_init\",\n",
    "                f\"mupc_param\",\n",
    "                f\"param_optim_{param_optim_id}\",\n",
    "                f\"param_lr_{mupc_param_lr}\",\n",
    "                f\"batch_size_{batch_size}\",\n",
    "                f\"{max_infer_iters}_max_infer_iters\",\n",
    "                f\"activity_optim_{activity_optim_id}\",\n",
    "                f\"activity_lr_{mupc_activity_lr}\",\n",
    "                f\"activity_decay_{activity_decay}\",\n",
    "                f\"weight_decay_{weight_decay}\",\n",
    "                f\"spectral_penalty_{spectral_penalty}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            if (n_hidden >= 64 and act_fn != \"tanh\") or (n_hidden == 32 and act_fn == \"linear\"):\n",
    "                 # chance for failed runs\n",
    "                pc_test_accs = np.array([10.] * 3)\n",
    "            else:\n",
    "                pc_test_accs = np.load(f\"{pc_save_path}/test_accs.npy\")\n",
    "                \n",
    "            mupc_test_accs = np.load(f\"{mupc_save_path}/test_accs.npy\") \n",
    "\n",
    "            if n_hidden == 128:\n",
    "                bp_lr = 1e-3 if act_fn == \"linear\" else 1e-2\n",
    "                bp_save_path = os.path.join(\n",
    "                    \"bp_results\",\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    f\"depth_mup_param\",\n",
    "                    param_optim_id,\n",
    "                    f\"lr_{bp_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                bp_test_accs = np.load(f\"{bp_save_path}/test_accs.npy\")   \n",
    "                bp_test_accs_all_seeds[seed] = bp_test_accs\n",
    "            \n",
    "            pc_test_accs_all_seeds[seed] = pc_test_accs\n",
    "            mupc_test_accs_all_seeds[seed] = mupc_test_accs\n",
    "\n",
    "        pc_test_acc_means, pc_test_acc_stds = compute_metric_stats(pc_test_accs_all_seeds)\n",
    "        mupc_test_acc_means, mupc_test_acc_stds = compute_metric_stats(mupc_test_accs_all_seeds)\n",
    "        if n_hidden == 128:\n",
    "            bp_test_acc_means, bp_test_acc_stds = compute_metric_stats(bp_test_accs_all_seeds)\n",
    "        \n",
    "        pc_test_accs_per_H[n_hidden] = (pc_test_acc_means, pc_test_acc_stds)\n",
    "        mupc_test_accs_per_H[n_hidden] = (mupc_test_acc_means, mupc_test_acc_stds)\n",
    "        if n_hidden == 128:\n",
    "            bp_test_accs_per_H[n_hidden] = (bp_test_acc_means, bp_test_acc_stds)\n",
    "\n",
    "    plot_mupc_vs_pc_vs_bp_accs(\n",
    "        mupc_accs=mupc_test_accs_per_H, \n",
    "        pc_accs=pc_test_accs_per_H, \n",
    "        bp_accs=bp_test_accs_per_H,\n",
    "        test_every=test_every, \n",
    "        act_fn=act_fn,\n",
    "        save_path=f\"{results_dir}/{act_fn}_mupc_vs_pc_best_accs.pdf\", \n",
    "        height=350, \n",
    "        width=500,\n",
    "        show_bp=True,\n",
    "        show_pc=True,\n",
    "        show_mupc=True\n",
    "    )\n",
    "\n",
    "create_legend(\n",
    "    n_hiddens, \n",
    "    f\"{results_dir}/n_hiddens_blue_legend.pdf\", \n",
    "    colorscale=\"Blues\",  # reversed or not\n",
    "    starting_color=1,\n",
    "    marker_size=5, \n",
    "    fontsize=12, \n",
    "    height=50, \n",
    "    width=1000\n",
    ")\n",
    "create_legend(\n",
    "    n_hiddens, \n",
    "    f\"{results_dir}/n_hiddens_red_legend.pdf\", \n",
    "    colorscale=\"Reds\",\n",
    "    starting_color=2, # 2 if not reversed, 0 otherwise\n",
    "    marker_size=5, \n",
    "    fontsize=12, \n",
    "    height=50, \n",
    "    width=1000\n",
    ")\n",
    "create_legend(\n",
    "    n_hiddens, \n",
    "    f\"{results_dir}/n_hiddens_black_legend.pdf\", \n",
    "    colorscale=\"gray_r\",\n",
    "    starting_color=2,  # 2 if reversed, 0 otherwise\n",
    "    marker_size=5, \n",
    "    fontsize=12, \n",
    "    height=50, \n",
    "    width=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 128 relu net ($\\mu$PC vs PC vs BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mupc_vs_pc_vs_bp_accs_128_layer_net(\n",
    "        bp_accs, \n",
    "        pc_accs, \n",
    "        mupc_accs, \n",
    "        dataset,\n",
    "        test_every,\n",
    "        save_path, \n",
    "        height=300, \n",
    "        width=450\n",
    "):\n",
    "    n_iters = len(bp_accs[0])\n",
    "    iters = [t for t in range(n_iters)]\n",
    "\n",
    "    bp_color = \"#222A2A\"\n",
    "    pc_color = \"#EF553B\"\n",
    "    mupc_color = \"#636EFA\"\n",
    "\n",
    "    fig = go.Figure() \n",
    "    \n",
    "    bp_means, bp_stds = bp_accs[0], bp_accs[1]\n",
    "    pc_means, pc_stds = pc_accs[0], pc_accs[1]\n",
    "    mupc_means, mupc_stds = mupc_accs[0], mupc_accs[1]\n",
    "    \n",
    "    bp_y_upper, bp_y_lower = bp_means + bp_stds, bp_means - bp_stds\n",
    "    pc_y_upper, pc_y_lower = pc_means + pc_stds, pc_means - pc_stds\n",
    "    mupc_y_upper, mupc_y_lower = mupc_means + mupc_stds, mupc_means - mupc_stds\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(iters) + list(iters[::-1]),\n",
    "            y=list(bp_y_upper) + list(bp_y_lower[::-1]),\n",
    "            fill=\"toself\",\n",
    "            fillcolor=bp_color,\n",
    "            line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "            opacity=0.3\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(iters) + list(iters[::-1]),\n",
    "            y=list(pc_y_upper) + list(pc_y_lower[::-1]),\n",
    "            fill=\"toself\",\n",
    "            fillcolor=pc_color,\n",
    "            line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "            opacity=0.3\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(iters) + list(iters[::-1]),\n",
    "            y=list(mupc_y_upper) + list(mupc_y_lower[::-1]),\n",
    "            fill=\"toself\",\n",
    "            fillcolor=mupc_color,\n",
    "            line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "            opacity=0.3\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=iters,\n",
    "            y=bp_means,\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=2, color=bp_color),\n",
    "            name=\"$BP$\"\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=iters,\n",
    "            y=pc_means,\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, color=pc_color, dash=\"dash\"),\n",
    "            name=\"$PC$\"\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=iters,\n",
    "            y=mupc_means,\n",
    "            mode=\"markers\",\n",
    "            line=dict(width=2, color=mupc_color),\n",
    "            name=\"$\\mu PC$\"\n",
    "        )\n",
    "    )\n",
    "            \n",
    "    xtickvals = [0, int(iters[-1] / 2), iters[-1]]\n",
    "    if dataset == \"MNIST\":\n",
    "        xticktext = [(t+1) * test_every for t in xtickvals]\n",
    "        ytickvals = [10, 55, 100] if dataset == \"MNIST\" else [10, 45, 90]\n",
    "    else:\n",
    "        xticktext = [t+1 for t in xtickvals]\n",
    "        ytickvals = [10, 50, 90]\n",
    "        \n",
    "    fig.update_layout(\n",
    "        height=height,\n",
    "        width=width,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\" if dataset == \"MNIST\" else \"Epoch\",\n",
    "            tickvals=xtickvals,\n",
    "            ticktext=xticktext\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Test accuracy (%)\",\n",
    "            tickvals=ytickvals,\n",
    "            ticktext=ytickvals\n",
    "        ),\n",
    "        font=dict(size=16),\n",
    "        margin=dict(r=120)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"  # Fashion-MNIST\n",
    "width = 512\n",
    "n_hidden = 128\n",
    "act_fn =  \"relu\"\n",
    "use_skips = True\n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "max_infer_iters = n_hidden\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 5    # 5 or 15\n",
    "test_every = 300  # 300 or 900\n",
    "n_seeds = 3\n",
    "\n",
    "# NOTE: PC runs diverge with the above params for any lrs and dataset   \n",
    "# best lrs for relu\n",
    "pc_param_lr = 1e-1\n",
    "pc_activity_lr = 1e-2\n",
    "mupc_param_lr = 1e-1 if dataset == \"MNIST\" else 5e-2\n",
    "mupc_activity_lr = 5e-1\n",
    "bp_lr = 5e-3  # for both MNIST and Fashion-MNIST\n",
    "\n",
    "bp_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "pc_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "mupc_test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "for seed in range(n_seeds):\n",
    "\n",
    "    bp_save_path = os.path.join(\n",
    "        \"bp_results\",\n",
    "        dataset,\n",
    "        f\"width_{width}\",\n",
    "        f\"{n_hidden}_n_hidden\",\n",
    "        act_fn,\n",
    "        f\"depth_mup_param\",\n",
    "        param_optim_id,\n",
    "        f\"lr_{bp_lr}\",\n",
    "        f\"batch_size_{batch_size}\",\n",
    "        f\"{max_epochs}_epochs\",\n",
    "        str(seed)\n",
    "    )\n",
    "    pc_save_path = os.path.join(\n",
    "        results_dir,\n",
    "        dataset,\n",
    "        f\"width_{width}\",\n",
    "        f\"{n_hidden}_n_hidden\",\n",
    "        act_fn,\n",
    "        \"skips\" if use_skips else \"no_skips\",\n",
    "        f\"standard_weight_init\",\n",
    "        f\"sp_param\",\n",
    "        f\"param_optim_{param_optim_id}\",\n",
    "        f\"param_lr_{pc_param_lr}\",\n",
    "        f\"batch_size_{batch_size}\",\n",
    "        f\"{max_infer_iters}_max_infer_iters\",\n",
    "        f\"activity_optim_{activity_optim_id}\",\n",
    "        f\"activity_lr_{pc_activity_lr}\",\n",
    "        f\"activity_decay_{activity_decay}\",\n",
    "        f\"weight_decay_{weight_decay}\",\n",
    "        f\"spectral_penalty_{spectral_penalty}\",\n",
    "        f\"{max_epochs}_epochs\",\n",
    "        str(seed)\n",
    "    )\n",
    "    mupc_save_path = os.path.join(\n",
    "        results_dir,\n",
    "        dataset,\n",
    "        f\"width_{width}\",\n",
    "        f\"{n_hidden}_n_hidden\",\n",
    "        act_fn,\n",
    "        \"skips\" if use_skips else \"no_skips\",\n",
    "        f\"standard_gauss_weight_init\",\n",
    "        f\"mupc_param\",\n",
    "        f\"param_optim_{param_optim_id}\",\n",
    "        f\"param_lr_{mupc_param_lr}\",\n",
    "        f\"batch_size_{batch_size}\",\n",
    "        f\"{max_infer_iters}_max_infer_iters\",\n",
    "        f\"activity_optim_{activity_optim_id}\",\n",
    "        f\"activity_lr_{mupc_activity_lr}\",\n",
    "        f\"activity_decay_{activity_decay}\",\n",
    "        f\"weight_decay_{weight_decay}\",\n",
    "        f\"spectral_penalty_{spectral_penalty}\",\n",
    "        f\"{max_epochs}_epochs\",\n",
    "        str(seed)\n",
    "    )\n",
    "    bp_test_accs = np.load(f\"{bp_save_path}/test_accs.npy\")   \n",
    "    pc_test_accs = np.array([10.] * len(bp_test_accs))\n",
    "    mupc_test_accs = np.load(f\"{mupc_save_path}/test_accs.npy\") \n",
    "  \n",
    "    bp_test_accs_all_seeds[seed] = bp_test_accs\n",
    "    pc_test_accs_all_seeds[seed] = pc_test_accs\n",
    "    mupc_test_accs_all_seeds[seed] = mupc_test_accs\n",
    "\n",
    "bp_test_acc_stats = compute_metric_stats(bp_test_accs_all_seeds)\n",
    "pc_test_acc_stats = compute_metric_stats(pc_test_accs_all_seeds)\n",
    "mupc_test_acc_stats = compute_metric_stats(mupc_test_accs_all_seeds)\n",
    "\n",
    "plot_mupc_vs_pc_vs_bp_accs_128_layer_net(\n",
    "    bp_accs=bp_test_acc_stats, \n",
    "    pc_accs=pc_test_acc_stats, \n",
    "    mupc_accs=mupc_test_acc_stats, \n",
    "    dataset=dataset,\n",
    "    test_every=test_every,\n",
    "    save_path=f\"{results_dir}/{dataset}/mupc_vs_pc_vs_bp_128_relu_net.pdf\", \n",
    "    height=300, \n",
    "    width=425\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ best SP results for depth at fixed width N = 512 ############\n",
    "n_hiddens = [8, 16, 32, 64, 128]\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "\n",
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "width = 512\n",
    "use_skips = True\n",
    "weight_init = \"standard\"\n",
    "param_type = \"sp\"\n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "for act_fn in act_fns:\n",
    "    print()\n",
    "    test_accs_per_H = {} \n",
    "    for n_hidden in n_hiddens:\n",
    "        max_infer_iters = n_hidden\n",
    "        \n",
    "        test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "\n",
    "        # best lr based on act\n",
    "        if act_fn == \"linear\":\n",
    "            param_lr = 1e-2\n",
    "            activity_lr = 1e-2\n",
    "        \n",
    "        elif act_fn == \"tanh\":\n",
    "            if n_hidden == 8:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-2\n",
    "            elif n_hidden == 16:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-2\n",
    "            elif n_hidden == 32:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-1\n",
    "            elif n_hidden == 64:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-1\n",
    "            elif n_hidden == 128:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-1\n",
    "        \n",
    "        elif act_fn == \"relu\":\n",
    "            if n_hidden == 8:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-1\n",
    "            elif n_hidden == 16:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-2\n",
    "            elif n_hidden == 32:\n",
    "                param_lr = 1e-2\n",
    "                activity_lr = 1e-2\n",
    "            elif n_hidden == 64:\n",
    "                param_lr = 1e-1\n",
    "                activity_lr = 1e-2\n",
    "        \n",
    "        for seed in range(n_seeds):\n",
    "        \n",
    "            save_path = os.path.join(\n",
    "                results_dir,\n",
    "                dataset,\n",
    "                f\"width_{width}\",\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                act_fn,\n",
    "                \"skips\" if use_skips else \"no_skips\",\n",
    "                f\"{weight_init}_weight_init\",\n",
    "                f\"{param_type}_param\",\n",
    "                f\"param_optim_{param_optim_id}\",\n",
    "                f\"param_lr_{param_lr}\",\n",
    "                f\"batch_size_{batch_size}\",\n",
    "                f\"{max_infer_iters}_max_infer_iters\",\n",
    "                f\"activity_optim_{activity_optim_id}\",\n",
    "                f\"activity_lr_{activity_lr}\",\n",
    "                f\"activity_decay_{activity_decay}\",\n",
    "                f\"weight_decay_{weight_decay}\",\n",
    "                f\"spectral_penalty_{spectral_penalty}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            if (n_hidden >= 64 and act_fn != \"tanh\") or (n_hidden == 32 and act_fn == \"linear\"):\n",
    "                 # chance for failed runs\n",
    "                test_accs = np.array([10.] * 3)\n",
    "            else:\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "\n",
    "            test_accs_all_seeds[seed] = test_accs\n",
    "\n",
    "        test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "        print(f\"mean test accs for {act_fn} and H = {n_hidden}: {test_acc_means}\")\n",
    "        test_accs_per_H[n_hidden] = (test_acc_means, test_acc_stds)\n",
    "\n",
    "    plot_metric_per_iv(\n",
    "        metric=test_accs_per_H,\n",
    "        metric_id=\"test_acc\", \n",
    "        iv_id=\"n_hidden\",\n",
    "        test_every=test_every, \n",
    "        save_path=f\"{results_dir}/{dataset}/best_test_accs_depth_SP_{act_fn}.pdf\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BP with Depth-$\\mu$P baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate sweep for $N = 512$ and $H =8$.\n",
    "* MNIST: 1 epoch and 5 epochs (only relu)\n",
    "* Fashion-MNIST: 15 epochs (relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"bp_results\"\n",
    "dataset = \"Fashion-MNIST\"\n",
    "width = 512\n",
    "n_hidden = 8\n",
    "param_type = \"depth_mup\"\n",
    "optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "max_epochs = 15   # 1, 5 or 15\n",
    "test_every = 900  # 300 for MNIST, 900 Fashion\n",
    "n_seeds = 3\n",
    "\n",
    "act_fns = [\"relu\"]\n",
    "lrs = [1, 5e-1, 1e-1, 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4]\n",
    "\n",
    "for act_fn in act_fns:\n",
    "    test_accs_per_lr = {} \n",
    "    for lr in lrs:\n",
    "        \n",
    "        test_accs_all_seeds = [[] for seed in range(n_seeds)]\n",
    "        for seed in range(n_seeds):\n",
    "            save_dir = os.path.join(\n",
    "                results_dir,\n",
    "                dataset,\n",
    "                f\"width_{width}\",\n",
    "                f\"{n_hidden}_n_hidden\",\n",
    "                act_fn,\n",
    "                f\"{param_type}_param\",\n",
    "                optim_id,\n",
    "                f\"lr_{lr}\",\n",
    "                f\"batch_size_{batch_size}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            test_accs = np.load(f\"{save_dir}/test_accs.npy\")\n",
    "            if len(test_accs) > 1:\n",
    "                test_accs_all_seeds[seed] = test_accs\n",
    "            else:\n",
    "                test_accs_all_seeds[seed] = test_accs = np.array([10.] * 3)\n",
    "                        \n",
    "        test_acc_means, test_acc_stds = compute_metric_stats(test_accs_all_seeds)\n",
    "        test_accs_per_lr[lr] = (test_acc_means, test_acc_stds)\n",
    "    \n",
    "    plot_metric_per_iv(\n",
    "        metric=test_accs_per_lr,\n",
    "        metric_id=\"test_acc\", \n",
    "        iv_id=\"activity_lr\",\n",
    "        test_every=test_every, \n",
    "        save_path=f\"{results_dir}/{dataset}/{act_fn}_best_test_accs.pdf\",\n",
    "        height=400,\n",
    "        width=575\n",
    "    )\n",
    "\n",
    "# for MNIST:\n",
    "# for 1 epoch:\n",
    "# best linear: 1e-3\n",
    "# best tanh & relu: 1e-2\n",
    "# for 5 epochs best for relu: 5e-3\n",
    "\n",
    "# for Fashion: best for relu 15 epochs: 5e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Activity decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accs_per_activity_decay(accs, activity_decays, save_path):\n",
    "    means, stds = accs.mean(axis=0), accs.std(axis=0)\n",
    "    y_upper, y_lower = means + stds, means - stds\n",
    "    \n",
    "    n_iters = len(means)\n",
    "    iters = [t for t in range(n_iters)]\n",
    "    \n",
    "    color = \"#636EFA\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(iters) + list(iters[::-1]),\n",
    "            y=list(y_upper) + list(y_lower[::-1]),\n",
    "            fill=\"toself\",\n",
    "            fillcolor=color,\n",
    "            line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "            opacity=0.3\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=means,\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(width=2, color=color),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        height=300,\n",
    "        width=450,\n",
    "        xaxis=dict(\n",
    "            title=\"Activity decay\",\n",
    "            tickvals=iters,\n",
    "            ticktext=[str(v) for v in activity_decays]\n",
    "        ),\n",
    "        yaxis=dict(title=\"Test accuracy (%)\"),\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"pcn_results/MNIST/width_128/8_n_hidden/linear/no_skips/standard_weight_init/sp_param/param_optim_adam/param_lr_0.001/batch_size_64/500_max_infer_iters/activity_optim_gd/\"\n",
    "activity_lrs = [0.5, 0.1, 0.05]\n",
    "activity_decays = [1, 5e-1, 1e-1, 5e-2, 1e-2, 0]\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "n_seeds = 3\n",
    "\n",
    "for activity_lr in activity_lrs:\n",
    "\n",
    "    test_accs_seeds = np.zeros((n_seeds, len(activity_decays)))\n",
    "    for i, activity_decay in enumerate(activity_decays):\n",
    "        for seed in range(n_seeds):\n",
    "            \n",
    "            run_path = os.path.join(\n",
    "                save_path,\n",
    "                f\"activity_lr_{activity_lr}\",\n",
    "                f\"activity_decay_{activity_decay}\",\n",
    "                f\"weight_decay_{weight_decay}\",\n",
    "                f\"spectral_penalty_{spectral_penalty}\",\n",
    "                f\"{max_epochs}_epochs\",\n",
    "                str(seed)\n",
    "            )\n",
    "            test_accs = np.load(f\"{run_path}/test_accs.npy\")\n",
    "            test_accs_seeds[seed, i] = max(test_accs)\n",
    "\n",
    "        plot_accs_per_activity_decay(\n",
    "            test_accs_seeds, \n",
    "            activity_decays, \n",
    "            f\"{save_path}/activity_lr_{activity_lr}/max_test_accs_per_activity_decay.pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hyperparameter transfer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_rates_contour(\n",
    "        metric, \n",
    "        activity_lrs, \n",
    "        param_lrs, \n",
    "        metric_id, \n",
    "        save_path,\n",
    "        smooth_contours=True,\n",
    "        show_axes_label=False\n",
    "):\n",
    "    colorscale = \"RdBu_r\" if metric_id == \"loss\" else \"Greens\"\n",
    "    contours_coloring = \"heatmap\" if smooth_contours else \"fill\"\n",
    "\n",
    "    metric_min, metric_max = metric.min(), metric.max()\n",
    "    emin = int(np.floor(np.log10(metric_min)))\n",
    "    emax = int(np.ceil(np.log10(metric_max)))\n",
    "\n",
    "    num_ticks = 6\n",
    "    tickvals = np.linspace(emin, emax, num=num_ticks)\n",
    "    ticktext = [f\"10<sup>{e:.1f}</sup>\" for e in tickvals]\n",
    "\n",
    "    contour = go.Contour(\n",
    "        z=np.log10(metric),\n",
    "        x=activity_lrs,\n",
    "        y=param_lrs,\n",
    "        colorscale=colorscale,\n",
    "        showscale=True,\n",
    "        contours_coloring=contours_coloring,\n",
    "        colorbar=dict(\n",
    "            len=1.08,\n",
    "            title=\"Training loss\" if (\n",
    "                metric_id == \"loss\"\n",
    "            ) else \"Test accuracy (%)\",\n",
    "            title_side=\"right\",\n",
    "            tickfont=dict(size=16),\n",
    "            tickvals=tickvals,\n",
    "            ticktext=ticktext\n",
    "        )\n",
    "        # contours=dict(\n",
    "        #     showlabels=True,\n",
    "        #     labelfont=dict(\n",
    "        #         size=10, \n",
    "        #         color=\"white\"\n",
    "        #     ),\n",
    "        # )\n",
    "    )\n",
    "    fig = go.Figure(data=[contour])\n",
    "         \n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            nticks=5, \n",
    "            type=\"log\",\n",
    "            exponentformat=\"power\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            nticks=2, \n",
    "            type=\"log\",\n",
    "            exponentformat=\"power\"\n",
    "        ),\n",
    "        font=dict(size=18),\n",
    "        plot_bgcolor=\"white\",\n",
    "        width=500, \n",
    "        height=400,\n",
    "        margin=dict(\n",
    "            r=100, \n",
    "            b=100,\n",
    "            l=50, \n",
    "            t=80\n",
    "        )\n",
    "    )\n",
    "    if show_axes_label:\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Activity lr\",\n",
    "            yaxis_title=\"Weight lr\",\n",
    "        )\n",
    "   \n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "n_hidden = 8\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"μP\"\n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "max_infer_iters = 8\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 300\n",
    "n_seeds = 3\n",
    "\n",
    "widths = [2**i for i in range(6, 11)]\n",
    "param_lrs = [5e-1, 1e-1, 5e-2, 1e-2]\n",
    "activity_lrs = [1000, 500, 100, 50, 10, 5, 1, 5e-1, 1e-1, 5e-2, 1e-2]\n",
    "\n",
    "for act_fn in act_fns:     \n",
    "    for width in widths:\n",
    "\n",
    "        # to skip one failed run\n",
    "        if max_infer_iters == 500:\n",
    "            n_seeds = 2 if (\n",
    "                dataset == \"MNIST\" and act_fn == \"linear\" and width == 64\n",
    "            ) else 3\n",
    "            \n",
    "        min_train_losses = np.zeros((len(param_lrs), len(activity_lrs), n_seeds))\n",
    "        max_test_accs = np.zeros_like(min_train_losses)\n",
    "        for i, param_lr in enumerate(param_lrs):\n",
    "            for j, activity_lr in enumerate(activity_lrs):\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"1_skip\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    batch_train_losses = np.load(f\"{save_path}/batch_train_losses.npy\")\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "\n",
    "                    # to skip failed runs\n",
    "                    try:\n",
    "                        min_train_losses[i, j, seed] = min(batch_train_losses)\n",
    "                        max_test_accs[i, j, seed] = max(test_accs)\n",
    "                    except:\n",
    "                        print(f\"failed run for act fn {act_fn}, width = {width}, seed {seed}\")\n",
    "                        pass\n",
    "                    \n",
    "        plot_learning_rates_contour(\n",
    "            metric=min_train_losses.mean(axis=-1), \n",
    "            activity_lrs=activity_lrs, \n",
    "            param_lrs=param_lrs, \n",
    "            metric_id=\"loss\", \n",
    "            save_path=f\"{results_dir}/min_train_losses_over_lrs_{act_fn}_width_{width}.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: this can be used to plot both SP and muPC results ###\n",
    "results_dir = \"pcn_results\"\n",
    "dataset = \"MNIST\"\n",
    "act_fns = [\"linear\", \"tanh\", \"relu\"]\n",
    "width = 512\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"μP\" \n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "n_hiddens = [2**i for i in range(3, 8)]  #7 for SP\n",
    "param_lrs = [5e-1, 1e-1, 5e-2, 1e-2]\n",
    "activity_lrs = [1000, 500, 100, 50, 10, 5, 1, 5e-1, 1e-1, 5e-2, 1e-2]\n",
    "\n",
    "for act_fn in act_fns:     \n",
    "    for n_hidden in n_hiddens:\n",
    "        max_infer_iters = n_hidden\n",
    " \n",
    "        min_train_losses = np.zeros((len(param_lrs), len(activity_lrs), n_seeds))\n",
    "        max_test_accs = np.zeros_like(min_train_losses)\n",
    "        for i, param_lr in enumerate(param_lrs):\n",
    "            for j, activity_lr in enumerate(activity_lrs):\n",
    "                for seed in range(n_seeds):\n",
    "                \n",
    "                    save_path = os.path.join(\n",
    "                        results_dir,\n",
    "                        dataset,\n",
    "                        f\"width_{width}\",\n",
    "                        f\"{n_hidden}_n_hidden\",\n",
    "                        act_fn,\n",
    "                        \"1_skip\" if use_skips else \"no_skips\",\n",
    "                        f\"{weight_init}_weight_init\",\n",
    "                        f\"{param_type}_param\",\n",
    "                        f\"param_optim_{param_optim_id}\",\n",
    "                        f\"param_lr_{param_lr}\",\n",
    "                        f\"batch_size_{batch_size}\",\n",
    "                        f\"{max_infer_iters}_max_infer_iters\",\n",
    "                        f\"activity_optim_{activity_optim_id}\",\n",
    "                        f\"activity_lr_{activity_lr}\",\n",
    "                        f\"activity_decay_{activity_decay}\",\n",
    "                        f\"weight_decay_{weight_decay}\",\n",
    "                        f\"spectral_penalty_{spectral_penalty}\",\n",
    "                        f\"{max_epochs}_epochs\",\n",
    "                        str(seed)\n",
    "                    )\n",
    "                    batch_train_losses = np.load(f\"{save_path}/batch_train_losses.npy\")\n",
    "                    test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "\n",
    "                    # to skip failed runs\n",
    "                    try:\n",
    "                        min_train_losses[i, j, seed] = min(batch_train_losses)\n",
    "                        max_test_accs[i, j, seed] = max(test_accs)\n",
    "                    except:\n",
    "                        #print(f\"failed run for act fn {act_fn}, width = {width}, seed {seed}\")\n",
    "                        pass\n",
    "\n",
    "        plot_learning_rates_contour(\n",
    "            metric=min_train_losses.mean(axis=-1), \n",
    "            activity_lrs=activity_lrs, \n",
    "            param_lrs=param_lrs, \n",
    "            metric_id=\"loss\", \n",
    "            save_path=f\"{results_dir}/min_train_losses_over_lrs_{act_fn}_depth_{n_hidden}.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra plot for Fashion-MNIST ($H = 8, N = 512$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"pcn_results\"\n",
    "dataset = \"Fashion-MNIST\"\n",
    "act_fn = [\"linear\", \"tanh\", \"relu\"]\n",
    "n_hidden = 8\n",
    "width = 512\n",
    "use_skips = True\n",
    "weight_init = \"standard_gauss\"\n",
    "param_type = \"mupc\"\n",
    "param_optim_id = \"adam\"\n",
    "batch_size = 64\n",
    "max_infer_iters = 8\n",
    "activity_optim_id = \"gd\"\n",
    "activity_decay = 0\n",
    "weight_decay = 0\n",
    "spectral_penalty = 0\n",
    "max_epochs = 1\n",
    "test_every = 100\n",
    "n_seeds = 3\n",
    "\n",
    "param_lrs = [5e-1, 1e-1, 5e-2, 1e-2]\n",
    "activity_lrs = [1000, 500, 100, 50, 10, 5, 1, 5e-1, 1e-1, 5e-2, 1e-2]\n",
    "\n",
    "for act_fn in act_fns:     \n",
    "    min_train_losses = np.zeros((len(param_lrs), len(activity_lrs), n_seeds))\n",
    "    max_test_accs = np.zeros_like(min_train_losses)\n",
    "    for i, param_lr in enumerate(param_lrs):\n",
    "        for j, activity_lr in enumerate(activity_lrs):\n",
    "            for seed in range(n_seeds):\n",
    "            \n",
    "                save_path = os.path.join(\n",
    "                    results_dir,\n",
    "                    dataset,\n",
    "                    f\"width_{width}\",\n",
    "                    f\"{n_hidden}_n_hidden\",\n",
    "                    act_fn,\n",
    "                    \"skips\" if use_skips else \"no_skips\",\n",
    "                    f\"{weight_init}_weight_init\",\n",
    "                    f\"{param_type}_param\",\n",
    "                    f\"param_optim_{param_optim_id}\",\n",
    "                    f\"param_lr_{param_lr}\",\n",
    "                    f\"batch_size_{batch_size}\",\n",
    "                    f\"{max_infer_iters}_max_infer_iters\",\n",
    "                    f\"activity_optim_{activity_optim_id}\",\n",
    "                    f\"activity_lr_{activity_lr}\",\n",
    "                    f\"activity_decay_{activity_decay}\",\n",
    "                    f\"weight_decay_{weight_decay}\",\n",
    "                    f\"spectral_penalty_{spectral_penalty}\",\n",
    "                    f\"{max_epochs}_epochs\",\n",
    "                    str(seed)\n",
    "                )\n",
    "                batch_train_losses = np.load(f\"{save_path}/batch_train_losses.npy\")\n",
    "                test_accs = np.load(f\"{save_path}/test_accs.npy\")\n",
    "\n",
    "                # to skip failed runs\n",
    "                try:\n",
    "                    min_train_losses[i, j, seed] = min(batch_train_losses)\n",
    "                    max_test_accs[i, j, seed] = max(test_accs)\n",
    "                except:\n",
    "                    print(f\"failed run for act fn {act_fn}, width = {width}, seed {seed}\")\n",
    "                    pass\n",
    "                \n",
    "    plot_learning_rates_contour(\n",
    "        metric=min_train_losses.mean(axis=-1), \n",
    "        activity_lrs=activity_lrs, \n",
    "        param_lrs=param_lrs, \n",
    "        metric_id=\"loss\", \n",
    "        save_path=f\"{results_dir}/min_train_losses_over_lrs_{dataset}_{act_fn}_width_{width}.pdf\",\n",
    "        show_axes_label=False\n",
    "    )\n",
    "    plot_learning_rates_contour(\n",
    "        metric=max_test_accs.mean(axis=-1), \n",
    "        activity_lrs=activity_lrs, \n",
    "        param_lrs=param_lrs, \n",
    "        metric_id=\"accuracy\", \n",
    "        save_path=f\"{results_dir}/max_test_accs_over_lrs_{dataset}_{act_fn}_width_{width}.pdf\",\n",
    "        show_axes_label=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Theory energy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import TwoSlopeNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_iv(iv):\n",
    "    if iv == 1:\n",
    "        label = \"2^0\"\n",
    "    if iv == 2:\n",
    "        label = \"2^1\"\n",
    "    if iv == 4:\n",
    "        label = \"2^2\"\n",
    "    if iv == 8:\n",
    "        label = \"2^3\"\n",
    "    elif iv == 16:\n",
    "        label = \"2^4\"\n",
    "    elif iv == 32:\n",
    "        label = \"2^5\"\n",
    "    elif iv == 64:\n",
    "        label = \"2^6\"\n",
    "    elif iv == 128:\n",
    "        label = \"2^7\"\n",
    "    elif iv == 256:\n",
    "        label = \"2^8\"\n",
    "    elif iv == 512:\n",
    "        label = \"2^9\"\n",
    "    return label\n",
    "\n",
    "        \n",
    "def plot_loss_energy_ratio_phase_diagram(\n",
    "        metric, \n",
    "        colorbar_title, \n",
    "        param_type,\n",
    "        save_path, \n",
    "        cmap=\"inferno\",\n",
    "        title=None,\n",
    "        show_cells=False,\n",
    "        norm=None\n",
    "    ):\n",
    "    n_widths, n_hiddens = metric.shape[0], metric.shape[1]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(\n",
    "        metric, \n",
    "        norm=norm,\n",
    "        origin=\"lower\", \n",
    "        interpolation=\"bicubic\",\n",
    "        cmap=cmap\n",
    "    )\n",
    "    ax.set_xlabel(\"$H$\", fontsize=30, labelpad=15)\n",
    "    ax.set_ylabel(\"$N$\", fontsize=30, labelpad=15)\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=30, pad=20)\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\n",
    "        colorbar_title, \n",
    "        fontsize=30, \n",
    "        labelpad=15\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "    xtick_positions = [i for i in range(n_widths)]\n",
    "    ytick_positions = [i for i in range(n_hiddens)]\n",
    "    tick_labels = [f\"$2^{i}$\" for i in range(n_hiddens)]\n",
    "    \n",
    "    ax.set_xticks(xtick_positions)\n",
    "    ax.set_yticks(ytick_positions)\n",
    "    ax.set_xticklabels(tick_labels, fontsize=18)\n",
    "    ax.set_yticklabels(tick_labels, fontsize=18)\n",
    "\n",
    "    if show_cells:\n",
    "        for i in range(n_widths):\n",
    "            for j in range(n_hiddens):\n",
    "                plt.text(\n",
    "                    j, \n",
    "                    i, \n",
    "                    f\"{metric[i, j]:.2f}\", \n",
    "                    color=\"white\", \n",
    "                    ha=\"center\", \n",
    "                    va=\"center\", \n",
    "                    fontsize=8\n",
    "                )\n",
    "    \n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_metrics_per_iv(\n",
    "        first_metric,\n",
    "        second_metric,\n",
    "        ivs,\n",
    "        iv_id,\n",
    "        save_path,\n",
    "        plot_second_metric=True\n",
    "    ):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    n_train_iters = len(first_metric[ivs[0]])\n",
    "    train_iters = [i for i in range(n_train_iters)]\n",
    "    \n",
    "    n_ivs = len(ivs)\n",
    "    colorscale = \"Purples\" if plot_second_metric else \"Reds\"\n",
    "    colors = pc.sample_colorscale(colorscale, n_ivs + 3)[3:]\n",
    "    for i, iv in enumerate(ivs):\n",
    "        label = get_label_from_iv(iv)\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=train_iters,\n",
    "                y=first_metric[iv],\n",
    "                name=f\"${{{iv_id}}} = {{{label}}}$\",\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=2, color=colors[i]),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if plot_second_metric:\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=train_iters,\n",
    "                y=second_metric[ivs[-1]],\n",
    "                name=\"loss\",\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=1, color=\"#EF553B\"),\n",
    "                legendrank=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ticks = [0, int(train_iters[-1]/2), train_iters[-1]]\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        width=550,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\",\n",
    "            tickvals=ticks,\n",
    "            ticktext=ticks\n",
    "        ),\n",
    "        yaxis=dict(title=\"Equilib. energy\" if plot_second_metric else \"Loss\"),\n",
    "        font=dict(size=18),\n",
    "        margin=dict(r=140, b=90, l=110)\n",
    "    )\n",
    "    fig.write_image(save_path)\n",
    "\n",
    "\n",
    "def plot_loss_energy_ratio_over_training(\n",
    "        loss_energy_ratios,\n",
    "        ivs,\n",
    "        iv_id,\n",
    "        save_path\n",
    "    ):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    n_train_iters = len(loss_energy_ratios[ivs[0]])\n",
    "    train_iters = [i for i in range(n_train_iters)]\n",
    "    \n",
    "    n_ivs = len(ivs)\n",
    "    colors = pc.sample_colorscale(\"Viridis\", n_ivs + 3)[3:]  # Plasma or Inferno\n",
    "    for i, iv in enumerate(ivs):\n",
    "        label = get_label_from_iv(iv)\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "                x=train_iters,\n",
    "                y=loss_energy_ratios[iv],\n",
    "                name=f\"${{{iv_id}}} = {{{label}}}$\",\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=2, color=colors[i]),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ticks = [0, int(train_iters[-1]/2), train_iters[-1]]\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        width=550,\n",
    "        xaxis=dict(\n",
    "            title=\"Training iteration\",\n",
    "            tickvals=ticks,\n",
    "            ticktext=ticks\n",
    "        ),\n",
    "        yaxis=dict(title=\"Ratio\"),\n",
    "        font=dict(size=18),\n",
    "        margin=dict(r=140, b=90, l=110)\n",
    "    )\n",
    "    fig.write_image(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary depth & width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"energy_theory_results\"\n",
    "USE_SKIPS = True\n",
    "PARAM_OPTIM_ID = \"adam\"\n",
    "ACT_FN = \"linear\"\n",
    "\n",
    "PARAM_TYPE = \"sp\"   #\"mupc\", \n",
    "PARAM_LR = 1e-1 if PARAM_TYPE == \"mupc\" else 1e-4\n",
    "\n",
    "WIDTHS = [2**i for i in range(7)]\n",
    "N_HIDDENS = [2**i for i in range(7)]\n",
    "SEED = 4320\n",
    "\n",
    "DATASET_SIZE = 60000\n",
    "BATCH_SIZE = 64\n",
    "n_train_iters = DATASET_SIZE // BATCH_SIZE\n",
    "\n",
    "PLOT_TS = [0, 5, 10, 50, 100, 200, 450, 900]\n",
    "vmin = 1\n",
    "vmax = 10**3 if PARAM_TYPE == \"mupc\" else 10**7\n",
    "\n",
    "loss_energy_ratios_per_N_L = np.zeros(\n",
    "    (len(WIDTHS), \n",
    "     len(N_HIDDENS), \n",
    "     n_train_iters)\n",
    ")\n",
    "for i, width in enumerate(WIDTHS):\n",
    "    for j, n_hidden in enumerate(N_HIDDENS):\n",
    "        save_dir = os.path.join(\n",
    "            RESULTS_DIR,\n",
    "            ACT_FN,\n",
    "            f\"{PARAM_TYPE}\",\n",
    "            \"skips\" if USE_SKIPS else \"no_skips\",\n",
    "            PARAM_OPTIM_ID,\n",
    "            f\"param_lr_{PARAM_LR}\",\n",
    "            f\"width_{width}\",\n",
    "            f\"{n_hidden}_n_hidden\",\n",
    "            str(SEED)\n",
    "        )\n",
    "        loss_energy_ratios = np.load(f\"{save_dir}/loss_energy_ratios.npy\")\n",
    "        loss_energy_ratios_per_N_L[i, j] = loss_energy_ratios\n",
    "\n",
    "for t in PLOT_TS:\n",
    "    plot_loss_energy_ratio_phase_diagram(\n",
    "        loss_energy_ratios_per_N_L[:, :, t], \n",
    "        colorbar_title=\"$\\mathcal{L} / \\mathcal{F}^*$\", \n",
    "        param_type=PARAM_TYPE,\n",
    "        save_path=f\"{save_dir}/loss_energy_ratio_t_{t}.pdf\",\n",
    "        cmap=\"inferno\",\n",
    "        title=f\"$t = {{{t}}}$\",\n",
    "        show_cells=True if PARAM_TYPE == \"mupc\" else False,\n",
    "        norm=LogNorm(vmin=vmin, vmax=vmax)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary width, fix depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"energy_theory_results\"\n",
    "USE_SKIPS = True\n",
    "PARAM_OPTIM_ID = \"adam\"\n",
    "PARAM_LR = 1e-3\n",
    "\n",
    "ACT_FNS = [\"linear\", \"tanh\", \"relu\"]\n",
    "PARAM_TYPES = [\"sp\", \"mupc\"]\n",
    "WIDTHS = [2**i for i in range(10)]\n",
    "N_HIDDEN = 4\n",
    "SEED = 4320\n",
    "\n",
    "DATASET_SIZE = 60000\n",
    "BATCH_SIZE = 64\n",
    "n_train_iters = DATASET_SIZE // BATCH_SIZE\n",
    "\n",
    "losses_per_width = { n: np.zeros(n_train_iters) for n in WIDTHS }\n",
    "energies_per_width = { n: np.zeros(n_train_iters) for n in WIDTHS }\n",
    "loss_energy_ratios_per_width = { n: np.zeros(n_train_iters) for n in WIDTHS }\n",
    "for act_fn in ACT_FNS:\n",
    "    for param_type in PARAM_TYPES:\n",
    "        for width in WIDTHS:\n",
    "            save_dir = os.path.join(\n",
    "                RESULTS_DIR,\n",
    "                act_fn,\n",
    "                f\"{param_type}\",\n",
    "                \"skips\" if USE_SKIPS else \"no_skips\",\n",
    "                PARAM_OPTIM_ID,\n",
    "                f\"param_lr_{PARAM_LR}\",\n",
    "                f\"width_{width}\",\n",
    "                f\"{N_HIDDEN}_n_hidden\",\n",
    "                str(SEED)\n",
    "            )\n",
    "            losses = np.load(f\"{save_dir}/train_losses.npy\")\n",
    "            energies = np.load(f\"{save_dir}/train_energies.npy\")\n",
    "            loss_energy_ratios = np.load(f\"{save_dir}/loss_energy_ratios.npy\")\n",
    "            \n",
    "            losses_per_width[width] = losses\n",
    "            energies_per_width[width] = energies\n",
    "            loss_energy_ratios_per_width[width] = loss_energy_ratios\n",
    "\n",
    "        plot_metrics_per_iv(\n",
    "            first_metric=energies_per_width,\n",
    "            second_metric=losses_per_width,\n",
    "            ivs=WIDTHS[1::2],\n",
    "            iv_id=\"N\", \n",
    "            save_path=f\"{save_dir}/energies_per_width.pdf\",\n",
    "            plot_second_metric=True\n",
    "        )\n",
    "        plot_metrics_per_iv(\n",
    "            first_metric=losses_per_width,\n",
    "            second_metric=energies_per_width,\n",
    "            ivs=WIDTHS[1::2],\n",
    "            iv_id=\"N\", \n",
    "            save_path=f\"{save_dir}/losses_per_width.pdf\",\n",
    "            plot_second_metric=False\n",
    "        )\n",
    "        plot_loss_energy_ratio_over_training(\n",
    "            loss_energy_ratios=loss_energy_ratios_per_width,\n",
    "            ivs=WIDTHS[1::2],\n",
    "            iv_id=\"N\",\n",
    "            save_path=f\"{save_dir}/loss_energy_ratios_per_width.pdf\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
